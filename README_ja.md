# Python A2A

<div align="center">

[![PyPI version](https://img.shields.io/pypi/v/python-a2a.svg)](https://pypi.org/project/python-a2a/)
[![Python Versions](https://img.shields.io/pypi/pyversions/python-a2a.svg)](https://pypi.org/project/python-a2a/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![PyPI Downloads](https://static.pepy.tech/badge/python-a2a)](https://pepy.tech/project/python-a2a)
[![Documentation Status](https://readthedocs.org/projects/python-a2a/badge/?version=latest)](https://python-a2a.readthedocs.io/en/latest/?badge=latest)
[![Code style: black](https://img.shields.io/badge/code%20style-black-000000.svg)](https://github.com/psf/black)
[![Imports: isort](https://img.shields.io/badge/%20imports-isort-%231674b1?style=flat&labelColor=ef8336)](https://pycqa.github.io/isort/)
[![UV Compatible](https://img.shields.io/badge/UV-Compatible-5C63FF.svg)](https://github.com/astral-sh/uv)
[![GitHub stars](https://img.shields.io/github/stars/themanojdesai/python-a2a?style=social)](https://github.com/themanojdesai/python-a2a/stargazers)

  <p>
      <a href="README.md">English</a> | <a href="README_zh.md">ç®€ä½“ä¸­æ–‡</a> | <a href="README_ja.md">æ—¥æœ¬èª</a> | <a href="README_es.md">EspaÃ±ol</a> | <a href="README_de.md">Deutsch</a> | <a href="README_fr.md">FranÃ§ais</a>
      <!-- Add other languages here like: | <a href="README_de.md">Deutsch</a> -->
  </p>
  

**Google Agent-to-Agent (A2A) ãƒ—ãƒ­ãƒˆã‚³ãƒ«ã®å…¬å¼ Python å®Ÿè£…ã€Model Context Protocol (MCP) çµ±åˆ**

</div>

## ğŸŒŸ æ¦‚è¦

Python A2A ã¯ã€Google ã® [Agent-to-Agent (A2A) ãƒ—ãƒ­ãƒˆã‚³ãƒ«](https://google.github.io/A2A/) ã®åŒ…æ‹¬çš„ã§æœ¬ç•ªç’°å¢ƒå¯¾å¿œã®ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã§ã‚ã‚Šã€[Model Context Protocol (MCP)](https://contextual.ai/introducing-mcp/) ã¨ã®å®Œå…¨ãªã‚µãƒãƒ¼ãƒˆã‚’æä¾›ã—ã¾ã™ã€‚ã“ã®ãƒ—ãƒ­ãƒˆã‚³ãƒ«ã¯ã€è¤‡é›‘ãªå•é¡Œã‚’è§£æ±ºã™ã‚‹ãŸã‚ã« AI ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãŒã‚·ãƒ¼ãƒ ãƒ¬ã‚¹ã«å”åŠ›ã§ãã‚‹ã‚ˆã†ã«ã™ã‚‹ãŸã‚ã®ã™ã¹ã¦ã®æ©Ÿèƒ½ã‚’æä¾›ã—ã¾ã™ã€‚

A2A ãƒ—ãƒ­ãƒˆã‚³ãƒ«ã¯ã€AI ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆé–“ã®ç›¸äº’ä½œç”¨ã®ãŸã‚ã®æ¨™æº–çš„ãªé€šä¿¡å½¢å¼ã‚’ç¢ºç«‹ã—ã€MCP ã¯ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãŒå¤–éƒ¨ãƒ„ãƒ¼ãƒ«ã‚„ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ã«ã‚¢ã‚¯ã‚»ã‚¹ã™ã‚‹ãŸã‚ã®æ¨™æº–åŒ–ã•ã‚ŒãŸæ–¹æ³•ã‚’æä¾›ã™ã‚‹ã“ã¨ã§ã€ã“ã®æ©Ÿèƒ½ã‚’æ‹¡å¼µã—ã¾ã™ã€‚Python A2A ã¯ç›´æ„Ÿçš„ãª API ã‚’é€šã˜ã¦ã“ã‚Œã‚‰ã®ãƒ—ãƒ­ãƒˆã‚³ãƒ«ã‚’ç°¡å˜ã«ä½¿ç”¨ã§ãã‚‹ã‚ˆã†ã«ã—ã€ã“ã‚Œã‚‰ã® API ã‚’ä½¿ç”¨ã—ã¦è¤‡é›‘ãªãƒãƒ«ãƒã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚·ã‚¹ãƒ†ãƒ ã‚’æ§‹ç¯‰ã§ãã¾ã™ã€‚

## ğŸ“‹ v0.5.X ã§ã®æ–°æ©Ÿèƒ½

- **ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆç™ºè¦‹**: Google A2A ãƒ—ãƒ­ãƒˆã‚³ãƒ«ã¨ã®å®Œå…¨ãªäº’æ›æ€§ã‚’æŒã¤ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãƒ¬ã‚¸ã‚¹ãƒˆãƒªãŠã‚ˆã³ç™ºè¦‹ã®çµ„ã¿è¾¼ã¿ã‚µãƒãƒ¼ãƒˆ
- **LangChain çµ±åˆ**: LangChain ã®ãƒ„ãƒ¼ãƒ«ãŠã‚ˆã³ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã¨ã®ã‚·ãƒ¼ãƒ ãƒ¬ã‚¹ãªçµ±åˆ
- **æ‹¡å¼µã•ã‚ŒãŸãƒ„ãƒ¼ãƒ«ã‚¨ã‚³ã‚·ã‚¹ãƒ†ãƒ **: ä»»æ„ã®ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã§ LangChain ãŠã‚ˆã³ MCP ã®ãƒ„ãƒ¼ãƒ«ã‚’ä½¿ç”¨å¯èƒ½
- **å¼·åŒ–ã•ã‚ŒãŸã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆç›¸äº’é‹ç”¨æ€§**: A2A ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã¨ LangChain ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®å¤‰æ›
- **æ··åˆãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ ã‚¨ãƒ³ã‚¸ãƒ³**: ä¸¡æ–¹ã®ã‚¨ã‚³ã‚·ã‚¹ãƒ†ãƒ ã‚’çµ„ã¿åˆã‚ã›ãŸãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã®æ§‹ç¯‰
- **ç°¡ç´ åŒ–ã•ã‚ŒãŸã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆé–‹ç™º**: å³åº§ã«æ•°åƒã®äº‹å‰æ§‹ç¯‰æ¸ˆã¿ãƒ„ãƒ¼ãƒ«ã«ã‚¢ã‚¯ã‚»ã‚¹å¯èƒ½
- **é«˜åº¦ãªã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£**: ã‚µãƒ¼ãƒãƒ¼ã‚»ãƒ³ãƒ†ãƒƒãƒ‰ã‚¤ãƒ™ãƒ³ãƒˆ (SSE)ã€ã‚ˆã‚Šè‰¯ã„ã‚¨ãƒ©ãƒ¼å‡¦ç†ã€å …ç‰¢ãªãƒ•ã‚§ãƒ¼ãƒ«ã‚ªãƒ¼ãƒãƒ¼æ©Ÿæ§‹ã‚’å‚™ãˆãŸå¼·åŒ–ã•ã‚ŒãŸã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°
- **ã‚¿ã‚¹ã‚¯ãƒ™ãƒ¼ã‚¹ã®ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°**: å®Ÿæ™‚é–“ã§ã‚¿ã‚¹ã‚¯æ›´æ–°ã‚’ã‚¹ãƒˆãƒªãƒ¼ãƒ ã™ã‚‹æ–°ã—ã„ `tasks_send_subscribe` ãƒ¡ã‚½ãƒƒãƒ‰
- **ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ãƒãƒ£ãƒ³ã‚¯ API**: æ§‹é€ åŒ–ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ç”¨ã® `StreamingChunk` ã‚¯ãƒ©ã‚¹ã§æ”¹å–„ã•ã‚ŒãŸãƒãƒ£ãƒ³ã‚¯å‡¦ç†
- **ãƒãƒ«ãƒã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã‚µãƒãƒ¼ãƒˆ**: è¤‡æ•°ã®ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆé–“ã®è‡ªå‹•ç™ºè¦‹ãŠã‚ˆã³ãƒ•ã‚§ãƒ¼ãƒ«ã‚ªãƒ¼ãƒãƒ¼

## ğŸ“‹ v0.4.X ã§ã®æ–°æ©Ÿèƒ½

- **ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚·ã‚¹ãƒ†ãƒ **: æ–°ã—ã„ `AgentNetwork` ã‚¯ãƒ©ã‚¹ã§è¤‡æ•°ã®ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’ç®¡ç†ãŠã‚ˆã³ç™ºè¦‹
- **ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°**: `StreamingClient` ã‚’ä½¿ç”¨ã—ã¦ãƒ¬ã‚¹ãƒãƒ³ã‚·ãƒ–ãª UI ã§ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’å®Ÿè£…
- **ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ ã‚¨ãƒ³ã‚¸ãƒ³**: æ¡ä»¶åˆ†å²ãŠã‚ˆã³ä¸¦åˆ—å®Ÿè¡Œã‚’å‚™ãˆãŸæ–°ã—ã„ãƒ•uent API ã‚’ä½¿ç”¨ã—ã¦è¤‡é›‘ãªãƒãƒ«ãƒã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚’å®šç¾©
- **AI ãƒ‘ãƒ¯ãƒ¼ãƒ‰ ãƒ«ãƒ¼ã‚¿**: `AIAgentRouter` ã‚’ä½¿ç”¨ã—ã¦æœ€ã‚‚é©åˆ‡ãªã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã«ã‚¯ã‚¨ãƒªã‚’è‡ªå‹•ãƒ«ãƒ¼ãƒ†ã‚£ãƒ³ã‚°
- **ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³ ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹**: æ–°ã—ã„ CLI ãƒ„ãƒ¼ãƒ«ã§ã‚¿ãƒ¼ãƒŸãƒŠãƒ«ã‹ã‚‰ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’åˆ¶å¾¡
- **å¼·åŒ–ã•ã‚ŒãŸéåŒæœŸã‚µãƒãƒ¼ãƒˆ**: ãƒ©ã‚¤ãƒ–ãƒ©ãƒªå…¨ä½“ã§ã‚ˆã‚Šè‰¯ã„ async/await ã‚µãƒãƒ¼ãƒˆ
- **æ–°ã—ã„æ¥ç¶šã‚ªãƒ—ã‚·ãƒ§ãƒ³**: ã‚ˆã‚Šå …ç‰¢ãªã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆé€šä¿¡ã®ãŸã‚ã®æ”¹å–„ã•ã‚ŒãŸã‚¨ãƒ©ãƒ¼å‡¦ç†ãŠã‚ˆã³ãƒªãƒˆãƒ©ã‚¤ãƒ­ã‚¸ãƒƒã‚¯

## âœ¨ ãªãœ Python A2A ã‚’é¸ã¶ã®ã‹

- **å®Œå…¨ãªå®Ÿè£…**: å…¬å¼ A2A ä»•æ§˜ã‚’å®Œå…¨ã«å®Ÿè£…ã—ã€å¦¥å”ãªã—
- **ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆç™ºè¦‹**: ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚¨ã‚³ã‚·ã‚¹ãƒ†ãƒ ã‚’æ§‹ç¯‰ã™ã‚‹ãŸã‚ã®çµ„ã¿è¾¼ã¿ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãƒ¬ã‚¸ã‚¹ãƒˆãƒªãŠã‚ˆã³ç™ºè¦‹
- **MCP çµ±åˆ**: é«˜åº¦ãªãƒ„ãƒ¼ãƒ«ä½¿ç”¨ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®ãŸã‚ã® Model Context Protocol ã®ãƒ•ã‚¡ãƒ¼ã‚¹ãƒˆã‚¯ãƒ©ã‚¹ã‚µãƒãƒ¼ãƒˆ
- **ä¼æ¥­å‘ã‘**: æœ¬ç•ªç’°å¢ƒç”¨ã«æ§‹ç¯‰ã•ã‚Œã€å …ç‰¢ãªã‚¨ãƒ©ãƒ¼å‡¦ç†ãŠã‚ˆã³æ¤œè¨¼
- **ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯éä¾å­˜**: ä»»æ„ã® Python ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ (Flaskã€FastAPIã€Django ãªã©) ã§å‹•ä½œ
- **LLM ãƒ—ãƒ­ãƒã‚¤ãƒ€ã®æŸ”è»Ÿæ€§**: OpenAIã€Anthropicã€AWS Bedrock ãªã©ã¨ã®ãƒã‚¤ãƒ†ã‚£ãƒ–çµ±åˆ
- **æœ€å°é™ã®ä¾å­˜é–¢ä¿‚**: ã‚³ã‚¢æ©Ÿèƒ½ã«ã¯ `requests` ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã¿ãŒå¿…è¦
- **å„ªã‚ŒãŸé–‹ç™ºè€…ä½“é¨“**: åŒ…æ‹¬çš„ãªãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã€å‹ãƒ’ãƒ³ãƒˆã€ä¾‹

## ğŸ“¦ ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«

### pip ã‚’ä½¿ç”¨ (å¾“æ¥å‹)

ã™ã¹ã¦ã®ä¾å­˜é–¢ä¿‚ã‚’å«ã‚€åŸºæœ¬ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«:

```bash
pip install python-a2a  # LangChainã€MCP ãŠã‚ˆã³ä»–ã®çµ±åˆã‚’å«ã‚€
```

ã¾ãŸã¯ã€å¿…è¦ã«å¿œã˜ã¦ç‰¹å®šã®ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«:

```bash
# Flask ãƒ™ãƒ¼ã‚¹ã®ã‚µãƒ¼ãƒãƒ¼å¯¾å¿œ
pip install "python-a2a[server]"

# OpenAI çµ±åˆ
pip install "python-a2a[openai]"

# Anthropic Claude çµ±åˆ
pip install "python-a2a[anthropic]"

# AWS-Bedrock çµ±åˆ
pip install "python-a2a[bedrock]"

# MCP çµ±åˆ (Model Context Protocol)
pip install "python-a2a[mcp]"

# ã™ã¹ã¦ã®ã‚ªãƒ—ã‚·ãƒ§ãƒ³ä¾å­˜é–¢ä¿‚
pip install "python-a2a[all]"
```

### UV ã‚’ä½¿ç”¨ (æ¨å¥¨)

[UV](https://github.com/astral-sh/uv) ã¯ pip ã‚ˆã‚Šã‚‚é«˜é€Ÿã§ä¿¡é ¼æ€§ã®é«˜ã„ç¾ä»£çš„ãª Python ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ç®¡ç†ãƒ„ãƒ¼ãƒ«ã§ã™ã€‚UV ã§ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã™ã‚‹ã«ã¯:

```bash
# UV ãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ãªã„å ´åˆã¯ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
curl -LsSf https://astral.sh/uv/install.sh | sh

# åŸºæœ¬ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
uv install python-a2a
```

### é–‹ç™ºã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«

é–‹ç™ºç”¨ã«ã¯ UV ãŒæ¨å¥¨ã•ã‚Œã¾ã™:

```bash
# ãƒªãƒã‚¸ãƒˆãƒªã‚’ã‚¯ãƒ­ãƒ¼ãƒ³
git clone https://github.com/themanojdesai/python-a2a.git
cd python-a2a

# ä»®æƒ³ç’°å¢ƒã‚’ä½œæˆã—ã¦é–‹ç™ºä¾å­˜é–¢ä¿‚ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
uv venv
source .venv/bin/activate  # Windows ã®å ´åˆã¯ .venv\Scripts\activate
uv pip install -e ".[dev]"
```

> ğŸ’¡ **ãƒ’ãƒ³ãƒˆ**: ã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯ã‚’ã‚¯ãƒªãƒƒã‚¯ã—ã¦ã‚¯ãƒªãƒƒãƒ—ãƒœãƒ¼ãƒ‰ã«ã‚³ãƒ”ãƒ¼ã§ãã¾ã™ã€‚

## ğŸš€ ã‚¯ã‚¤ãƒƒã‚¯ã‚¹ã‚¿ãƒ¼ãƒˆä¾‹

### 1. ã‚¹ã‚­ãƒ«ä»˜ãã‚·ãƒ³ãƒ—ãƒ«ãª A2A ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®ä½œæˆ

```python
from python_a2a import A2AServer, skill, agent, run_server, TaskStatus, TaskState

@agent(
    name="Weather Agent",
    description="Provides weather information",
    version="1.0.0"
)
class WeatherAgent(A2AServer):
    
    @skill(
        name="Get Weather",
        description="Get current weather for a location",
        tags=["weather", "forecast"]
    )
    def get_weather(self, location):
        """Get weather for a location."""
        # ãƒ¢ãƒƒã‚¯å®Ÿè£…
        return f"It's sunny and 75Â°F in {location}"
    
    def handle_task(self, task):
        # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‹ã‚‰å ´æ‰€ã‚’æŠ½å‡º
        message_data = task.message or {}
        content = message_data.get("content", {})
        text = content.get("text", "") if isinstance(content, dict) else ""
        
        if "weather" in text.lower() and "in" in text.lower():
            location = text.split("in", 1)[1].strip().rstrip("?.")
            
            # å¤©æ°—ã‚’å–å¾—ã—ã¦å¿œç­”ã‚’ä½œæˆ
            weather_text = self.get_weather(location)
            task.artifacts = [{
                "parts": [{"type": "text", "text": weather_text}]
            }]
            task.status = TaskStatus(state=TaskState.COMPLETED)
        else:
            task.status = TaskStatus(
                state=TaskState.INPUT_REQUIRED,
                message={"role": "agent", "content": {"type": "text", 
                         "text": "Please ask about weather in a specific location."}}
            )
        return task

# ã‚µãƒ¼ãƒãƒ¼ã‚’èµ·å‹•
if __name__ == "__main__":
    agent = WeatherAgent()
    run_server(agent, port=5000)
```

### 2. è¤‡æ•°ã®ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã§ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã®æ§‹ç¯‰

```python
from python_a2a import AgentNetwork, A2AClient, AIAgentRouter

# ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã®ä½œæˆ
network = AgentNetwork(name="Travel Assistant Network")

# ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã«ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’è¿½åŠ 
network.add("weather", "http://localhost:5001")
network.add("hotels", "http://localhost:5002")
network.add("attractions", "http://localhost:5003")

# ã‚¯ã‚¨ãƒªã‚’æœ€é©ãªã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã«ãƒ«ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ã™ã‚‹ãƒ«ãƒ¼ã‚¿ã®ä½œæˆ
router = AIAgentRouter(
    llm_client=A2AClient("http://localhost:5000/openai"),  # ãƒ«ãƒ¼ãƒ†ã‚£ãƒ³ã‚°æ±ºå®šç”¨ã® LLM
    agent_network=network
)

# ã‚¯ã‚¨ãƒªã‚’é©åˆ‡ãªã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã«ãƒ«ãƒ¼ãƒ†ã‚£ãƒ³ã‚°
agent_name, confidence = router.route_query("What's the weather like in Paris?")
print(f"{agent_name} ã« {confidence:.2f} ã®ä¿¡é ¼åº¦ã§ãƒ«ãƒ¼ãƒ†ã‚£ãƒ³ã‚°")

# é¸æŠã•ã‚ŒãŸã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã«è³ªå•
agent = network.get_agent(agent_name)
response = agent.ask("What's the weather like in Paris?")
print(f"å¿œç­”: {response}")

# åˆ©ç”¨å¯èƒ½ãªã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’ä¸€è¦§è¡¨ç¤º
print("\nåˆ©ç”¨å¯èƒ½ãªã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ:")
for agent_info in network.list_agents():
    print(f"- {agent_info['name']}: {agent_info['description']}")
```

### å®Ÿæ™‚é–“ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°

ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‹ã‚‰å®Ÿæ™‚é–“ã®å¿œç­”ã‚’å–å¾—ã™ã‚‹åŒ…æ‹¬çš„ãªã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ã‚µãƒãƒ¼ãƒˆ:

```python
import asyncio
from python_a2a import StreamingClient, Message, TextContent, MessageRole

async def main():
    client = StreamingClient("http://localhost:5000")
    
    # å¿…è¦ãª role ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’æŒã¤ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®ä½œæˆ
    message = Message(
        content=TextContent(text="Tell me about A2A streaming"),
        role=MessageRole.USER
    )
    
    # å¿œç­”ã‚’ã‚¹ãƒˆãƒªãƒ¼ãƒ ã—ã¦ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã§ãƒãƒ£ãƒ³ã‚¯ã‚’å‡¦ç†
    try:
        async for chunk in client.stream_response(message):
            # ç•°ãªã‚‹ãƒãƒ£ãƒ³ã‚¯å½¢å¼ (æ–‡å­—åˆ—ã¾ãŸã¯è¾æ›¸) ã‚’å‡¦ç†
            if isinstance(chunk, dict):
                if "content" in chunk:
                    print(chunk["content"], end="", flush=True)
                elif "text" in chunk:
                    print(chunk["text"], end="", flush=True)
                else:
                    print(str(chunk), end="", flush=True)
            else:
                print(str(chunk), end="", flush=True)
    except Exception as e:
        print(f"ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ã‚¨ãƒ©ãƒ¼: {e}")
```

`examples/streaming/` ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«å®Œå…¨ãªã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ä¾‹ãŒã‚ã‚Šã¾ã™:

- **basic_streaming.py**: æœ€å°é™ã®ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å®Ÿè£… (ã“ã“ã‹ã‚‰å§‹ã‚ã¾ã—ã‚‡ã†!)
- **01_basic_streaming.py**: ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ã®åŸºæœ¬ã®åŒ…æ‹¬çš„ãªå°å…¥
- **02_advanced_streaming.py**: ç•°ãªã‚‹ãƒãƒ£ãƒ³ã‚­ãƒ³ã‚°æˆ¦ç•¥ã‚’ä½¿ç”¨ã—ãŸé«˜åº¦ãªã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°
- **03_streaming_llm_integration.py**: LLM ãƒ—ãƒ­ãƒã‚¤ãƒ€ã¨ã®ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°çµ±åˆ
- **04_task_based_streaming.py**: é€²è¡ŒçŠ¶æ³è¿½è·¡ä»˜ãã‚¿ã‚¹ã‚¯ãƒ™ãƒ¼ã‚¹ã®ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°
- **05_streaming_ui_integration.py**: ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚° UI çµ±åˆ (CLI ãŠã‚ˆã³ Web)
- **06_distributed_streaming.py**: åˆ†æ•£ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£

### 3. ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ ã‚¨ãƒ³ã‚¸ãƒ³

æ–°ã—ã„ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ ã‚¨ãƒ³ã‚¸ãƒ³ã«ã‚ˆã‚Šã€è¤‡é›‘ãªã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆç›¸äº’ä½œç”¨ã‚’å®šç¾©ã§ãã¾ã™:

```python
from python_a2a import AgentNetwork, Flow
import asyncio

async def main():
    # ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã®è¨­å®š
    network = AgentNetwork()
    network.add("research", "http://localhost:5001")
    network.add("summarizer", "http://localhost:5002")
    network.add("factchecker", "http://localhost:5003")
    
    # ç ”ç©¶ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆã®ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã®å®šç¾©
    flow = Flow(agent_network=network, name="Research Report Workflow")
    
    # æœ€åˆã«åˆæœŸç ”ç©¶ã‚’åé›†
    flow.ask("research", "Research the latest developments in {topic}")
    
    # çµæœã‚’ä¸¦åˆ—å‡¦ç†
    parallel_results = (flow.parallel()
        # ãƒ–ãƒ©ãƒ³ãƒ 1: è¦ç´„ã‚’ä½œæˆ
        .ask("summarizer", "Summarize this research: {latest_result}")
        # ãƒ–ãƒ©ãƒ³ãƒ 2: ä¸»ãªäº‹å®Ÿã‚’æ¤œè¨¼
        .branch()
        .ask("factchecker", "Verify these key facts: {latest_result}")
        # ä¸¦åˆ—å‡¦ç†ã‚’çµ‚äº†ã—ã¦çµæœã‚’åé›†
        .end_parallel(max_concurrency=2))
    
    # æ¤œè¨¼çµæœã«åŸºã¥ã„ã¦ã‚¤ãƒ³ã‚µã‚¤ãƒˆã‚’æŠ½å‡º
    flow.execute_function(
        lambda results, context: f"Summary: {results['1']}\nVerified Facts: {results['2']}",
        parallel_results
    )
    
    # ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã®å®Ÿè¡Œ
    result = await flow.run({
        "topic": "quantum computing advancements in the last year"
    })
    
    print(result)

if __name__ == "__main__":
    asyncio.run(main())
```

### 4. AI ãƒ‘ãƒ¯ãƒ¼ãƒ‰ ãƒ«ãƒ¼ã‚¿

å„ã‚¯ã‚¨ãƒªã«æœ€é©ãªã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’é¸æŠã™ã‚‹ã‚¤ãƒ³ãƒ†ãƒªã‚¸ã‚§ãƒ³ãƒˆ ãƒ«ãƒ¼ãƒ†ã‚£ãƒ³ã‚°:

```python
from python_a2a import AgentNetwork, AIAgentRouter, A2AClient
import asyncio

async def main():
    # å°‚é–€åˆ†é‡åˆ¥ã®ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’æŒã¤ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã®ä½œæˆ
    network = AgentNetwork()
    network.add("math", "http://localhost:5001")
    network.add("history", "http://localhost:5002")
    network.add("science", "http://localhost:5003")
    network.add("literature", "http://localhost:5004")
    
    # LLM ã‚’ä½¿ç”¨ã—ã¦æ„æ€æ±ºå®šã‚’è¡Œã†ãƒ«ãƒ¼ã‚¿ã®ä½œæˆ
    router = AIAgentRouter(
        llm_client=A2AClient("http://localhost:5000/openai"),
        agent_network=network
    )
    
    # ãƒ«ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ã™ã‚‹ã‚µãƒ³ãƒ—ãƒ«ã‚¯ã‚¨ãƒª
    queries = [
        "What is the formula for the area of a circle?",
        "Who wrote The Great Gatsby?",
        "When did World War II end?",
        "How does photosynthesis work?",
        "What are Newton's laws of motion?"
    ]
    
    # å„ã‚¯ã‚¨ãƒªã‚’æœ€é©ãªã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã«ãƒ«ãƒ¼ãƒ†ã‚£ãƒ³ã‚°
    for query in queries:
        agent_name, confidence = router.route_query(query)
        agent = network.get_agent(agent_name)
        
        print(f"ã‚¯ã‚¨ãƒª: {query}")
        print(f"ãƒ«ãƒ¼ãƒ†ã‚£ãƒ³ã‚°å…ˆ: {agent_name} (ä¿¡é ¼åº¦: {confidence:.2f})")
        
        # é¸æŠã•ã‚ŒãŸã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‹ã‚‰å¿œç­”ã‚’å–å¾—
        response = agent.ask(query)
        print(f"å¿œç­”: {response[:100]}...\n")

if __name__ == "__main__":
    asyncio.run(main())
```

### 5. è¤‡æ•°ã®ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã§è¤‡é›‘ãªãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã®å®šç¾©

```python
from python_a2a import AgentNetwork, Flow, AIAgentRouter
import asyncio

async def main():
    # ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã®ä½œæˆ
    network = AgentNetwork()
    network.add("weather", "http://localhost:5001")
    network.add("recommendations", "http://localhost:5002")
    network.add("booking", "http://localhost:5003")
    
    # ãƒ«ãƒ¼ã‚¿ã®ä½œæˆ
    router = AIAgentRouter(
        llm_client=network.get_agent("weather"),  # ãƒ«ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ç”¨ã« 1 ã¤ã®ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’ LLM ã¨ã—ã¦ä½¿ç”¨
        agent_network=network
    )
    
    # æ¡ä»¶ä»˜ããƒ­ã‚¸ãƒƒã‚¯ã‚’æŒã¤ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã®å®šç¾©
    flow = Flow(agent_network=network, router=router, name="Travel Planning Workflow")
    
    # æœ€åˆã«å¤©æ°—ã‚’å–å¾—
    flow.ask("weather", "What's the weather in {destination}?")
    
    # å¤©æ°—ã«åŸºã¥ã„ã¦æ¡ä»¶åˆ†å²
    flow.if_contains("sunny")
    
    # æ™´ã‚Œã¦ã„ã‚Œã°å±‹å¤–ã‚¢ã‚¯ãƒ†ã‚£ãƒ“ãƒ†ã‚£ã‚’æ¨å¥¨
    flow.ask("recommendations", "Recommend outdoor activities in {destination}")
    
    # æ¡ä»¶ã‚’çµ‚äº†ã—ã¦ else ãƒ–ãƒ©ãƒ³ãƒã‚’è¿½åŠ 
    flow.else_branch()
    
    # æ™´ã‚Œã¦ã„ãªã„å ´åˆã¯å±‹å†…ã‚¢ã‚¯ãƒ†ã‚£ãƒ“ãƒ†ã‚£ã‚’æ¨å¥¨
    flow.ask("recommendations", "Recommend indoor activities in {destination}")
    
    # if-else ãƒ–ãƒ­ãƒƒã‚¯ã‚’çµ‚äº†
    flow.end_if()
    
    # ä¸¦åˆ—å‡¦ç†ã‚¹ãƒ†ãƒƒãƒ—ã‚’è¿½åŠ 
    (flow.parallel()
        .ask("booking", "Find hotels in {destination}")
        .branch()
        .ask("booking", "Find restaurants in {destination}")
        .end_parallel())
    
    # åˆæœŸã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã§ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚’å®Ÿè¡Œ
    result = await flow.run({
        "destination": "Paris",
        "travel_dates": "June 12-20"
    })
    
    print("ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã®çµæœ:")
    print(result)

if __name__ == "__main__":
    asyncio.run(main())
```

### 6. ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³ ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ã®ä½¿ç”¨

```bash
# ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã«ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’é€ä¿¡
a2a send http://localhost:5000 "What is artificial intelligence?"

# å®Ÿæ™‚é–“ã§å¿œç­”ã‚’ã‚¹ãƒˆãƒªãƒ¼ãƒ 
a2a stream http://localhost:5000 "Generate a step-by-step tutorial for making pasta"

# OpenAI ãƒ‘ãƒ¯ãƒ¼ãƒ‰ A2A ã‚µãƒ¼ãƒãƒ¼ã‚’èµ·å‹•
a2a openai --model gpt-4 --system-prompt "You are a helpful coding assistant"

# Anthropic ãƒ‘ãƒ¯ãƒ¼ãƒ‰ A2A ã‚µãƒ¼ãƒãƒ¼ã‚’èµ·å‹•
a2a anthropic --model claude-3-opus-20240229 --system-prompt "You are a friendly AI teacher"

# ãƒ„ãƒ¼ãƒ«ä»˜ã MCP ã‚µãƒ¼ãƒãƒ¼ã‚’èµ·å‹•
a2a mcp-serve --name "Data Analysis MCP" --port 5001 --script analysis_tools.py

# MCP å¯¾å¿œ A2A ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’èµ·å‹•
a2a mcp-agent --servers data=http://localhost:5001 calc=http://localhost:5002

# MCP ãƒ„ãƒ¼ãƒ«ã‚’ç›´æ¥å‘¼ã³å‡ºã™
a2a mcp-call http://localhost:5001 analyze_csv --params file=data.csv columns=price,date

# ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚’ç®¡ç†
a2a network --add weather=http://localhost:5001 travel=http://localhost:5002 --save network.json

# ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‹ã‚‰ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚’å®Ÿè¡Œ
a2a workflow --script research_workflow.py --context initial_data.json
```

## ğŸ”„ LangChain çµ±åˆ (v0.5.X ã§æ–°è¦)

Python A2A ã«ã¯çµ„ã¿è¾¼ã¿ã® LangChain çµ±åˆãŒå«ã¾ã‚Œã¦ãŠã‚Šã€ä¸¡æ–¹ã®ã‚¨ã‚³ã‚·ã‚¹ãƒ†ãƒ ã®æœ€è‰¯éƒ¨åˆ†ã‚’ç°¡å˜ã«çµ„ã¿åˆã‚ã›ã‚‹ã“ã¨ãŒã§ãã¾ã™:

### 1. MCP ãƒ„ãƒ¼ãƒ«ã‚’ LangChain ã«å¤‰æ›

```python
from python_a2a.mcp import FastMCP, text_response
from python_a2a.langchain import to_langchain_tool

# MCP ã‚µãƒ¼ãƒãƒ¼ã«ãƒ„ãƒ¼ãƒ«ã‚’ä½œæˆ
mcp_server = FastMCP(name="Basic Tools", description="Simple utility tools")

@mcp_server.tool(
    name="calculator",
    description="Calculate a mathematical expression"
)
def calculator(input):
    """Simple calculator that evaluates an expression."""
    try:
        result = eval(input)
        return text_response(f"Result: {result}")
    except Exception as e:
        return text_response(f"Error: {e}")

# ã‚µãƒ¼ãƒãƒ¼ã‚’èµ·å‹•
import threading, time
def run_server(server, port):
    server.run(host="0.0.0.0", port=port)
server_thread = threading.Thread(target=run_server, args=(mcp_server, 5000), daemon=True)
server_thread.start()
time.sleep(2)  # ã‚µãƒ¼ãƒãƒ¼ã®èµ·å‹•ã‚’å¾…ã¤

# MCP ãƒ„ãƒ¼ãƒ«ã‚’ LangChain ã«å¤‰æ›
calculator_tool = to_langchain_tool("http://localhost:5000", "calculator")

# LangChain ã§ãƒ„ãƒ¼ãƒ«ã‚’ä½¿ç”¨
result = calculator_tool.run("5 * 9 + 3")
print(f"Result: {result}")
```

### 2. LangChain ãƒ„ãƒ¼ãƒ«ã‚’ MCP ã‚µãƒ¼ãƒãƒ¼ã«å¤‰æ›

```python
from langchain.tools import Tool
from langchain_core.tools import BaseTool
from python_a2a.langchain import to_mcp_server

# LangChain ãƒ„ãƒ¼ãƒ«ã‚’ä½œæˆ
def calculator(expression: str) -> str:
    """Evaluate a mathematical expression"""
    try:
        result = eval(expression)
        return f"Result: {expression} = {result}"
    except Exception as e:
        return f"Error: {e}"

calculator_tool = Tool(
    name="calculator",
    description="Evaluate a mathematical expression",
    func=calculator
)

# MCP ã‚µãƒ¼ãƒãƒ¼ã«å¤‰æ›
mcp_server = to_mcp_server(calculator_tool)

# ã‚µãƒ¼ãƒãƒ¼ã‚’èµ·å‹•
mcp_server.run(port=5000)
```

### 3. LangChain ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã‚’ A2A ã‚µãƒ¼ãƒãƒ¼ã«å¤‰æ›

```python
from langchain_openai import ChatOpenAI
from langchain_core.output_parsers import StrOutputParser
from langchain_core.prompts import PromptTemplate
from python_a2a import A2AClient, run_server
from python_a2a.langchain import to_a2a_server

# LangChain LLM ã‚’ä½œæˆ
llm = ChatOpenAI(model="gpt-3.5-turbo", temperature=0)

# LLM ã‚’ A2A ã‚µãƒ¼ãƒãƒ¼ã«å¤‰æ›
llm_server = to_a2a_server(llm)

# ç°¡å˜ãªãƒã‚§ãƒ¼ãƒ³ã‚’ä½œæˆ
template = "You are a helpful travel guide.\n\nQuestion: {query}\n\nAnswer:"
prompt = PromptTemplate.from_template(template)
travel_chain = prompt | llm | StrOutputParser()

# ãƒã‚§ãƒ¼ãƒ³ã‚’ A2A ã‚µãƒ¼ãƒãƒ¼ã«å¤‰æ›
travel_server = to_a2a_server(travel_chain)

# èƒŒæ™¯ã‚¹ãƒ¬ãƒƒãƒ‰ã§ã‚µãƒ¼ãƒãƒ¼ã‚’å®Ÿè¡Œ
import threading
llm_thread = threading.Thread(
    target=lambda: run_server(llm_server, port=5001),
    daemon=True
)
llm_thread.start()

travel_thread = threading.Thread(
    target=lambda: run_server(travel_server, port=5002),
    daemon=True
)
travel_thread.start()

# ã‚µãƒ¼ãƒãƒ¼ã‚’ãƒ†ã‚¹ãƒˆ
llm_client = A2AClient("http://localhost:5001")
travel_client = A2AClient("http://localhost:5002")

llm_result = llm_client.ask("What is the capital of France?")
travel_result = travel_client.ask('{"query": "What are some must-see attractions in Paris?"}')
```

### 4. A2A ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’ LangChain ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã«å¤‰æ›

```python
from python_a2a.langchain import to_langchain_agent

# A2A ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’ LangChain ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã«å¤‰æ›
langchain_agent = to_langchain_agent("http://localhost:5000")

# LangChain ã§ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’ä½¿ç”¨
result = langchain_agent.invoke("What are some famous landmarks in Paris?")
print(result.get('output', ''))

# LangChain ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã§ä½¿ç”¨
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser

llm = ChatOpenAI(temperature=0)
prompt = ChatPromptTemplate.from_template(
    "Generate a specific, detailed travel question about {destination}."
)

# å¤‰æ›ã•ã‚ŒãŸã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’å«ã‚€ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã®ä½œæˆ
chain = (
    prompt |
    llm |
    StrOutputParser() |
    langchain_agent |
    (lambda x: f"Travel Info: {x.get('output', '')}")
)

result = chain.invoke({"destination": "Japan"})
print(result)
```

LangChain ã¯ python-a2a ã«è‡ªå‹•çš„ã«ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã‚‹ãŸã‚ã€ã™ã¹ã¦ãŒã™ãã«å‹•ä½œã—ã¾ã™:

```bash
pip install python-a2a
# ãã‚Œã ã‘ã§å®Œäº†ã§ã™! LangChain ã¯è‡ªå‹•çš„ã«å«ã¾ã‚Œã¾ã™
```

## ğŸ§© ã‚³ã‚¢æ©Ÿèƒ½

### ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯

Python A2A ã«ã¯ã€è¤‡æ•°ã®ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’ç®¡ç†ã™ã‚‹ãŸã‚ã®å¼·åŠ›ãªã‚·ã‚¹ãƒ†ãƒ ãŒå«ã¾ã‚Œã¦ã„ã¾ã™:

```python
from python_a2a import AgentNetwork, A2AClient

# ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã®ä½œæˆ
network = AgentNetwork(name="Medical Assistant Network")

# ç•°ãªã‚‹æ–¹æ³•ã§ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’è¿½åŠ 
network.add("diagnosis", "http://localhost:5001")  # URL ã‹ã‚‰
network.add("medications", A2AClient("http://localhost:5002"))  # ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‹ã‚‰

# URL ãƒªã‚¹ãƒˆã‹ã‚‰ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’ç™ºè¦‹
discovered_count = network.discover_agents([
    "http://localhost:5003",
    "http://localhost:5004",
    "http://localhost:5005"
])
print(f"{discovered_count} å€‹ã®æ–°ã—ã„ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’ç™ºè¦‹ã—ã¾ã—ãŸ")

# ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯å†…ã®ã™ã¹ã¦ã®ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’ä¸€è¦§è¡¨ç¤º
for agent_info in network.list_agents():
    print(f"ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ: {agent_info['name']}")
    print(f"URL: {agent_info['url']}")
    if 'description' in agent_info:
        print(f"èª¬æ˜: {agent_info['description']}")
    print()

# ç‰¹å®šã®ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’å–å¾—
agent = network.get_agent("diagnosis")
response = agent.ask("What are the symptoms of the flu?")
```

### 7. ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆç™ºè¦‹ãŠã‚ˆã³ãƒ¬ã‚¸ã‚¹ãƒˆãƒª

```python
from python_a2a import AgentCard, A2AServer, run_server
from python_a2a.discovery import AgentRegistry, run_registry, enable_discovery, DiscoveryClient
import threading
import time

# ãƒ¬ã‚¸ã‚¹ãƒˆãƒªã‚µãƒ¼ãƒãƒ¼ã®ä½œæˆ
registry = AgentRegistry(
    name="A2A ãƒ¬ã‚¸ã‚¹ãƒˆãƒªã‚µãƒ¼ãƒãƒ¼",
    description="ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆç™ºè¦‹ã®ãŸã‚ã®ä¸­å¤®ãƒ¬ã‚¸ã‚¹ãƒˆãƒª"
)

# ãƒ¬ã‚¸ã‚¹ãƒˆãƒªã‚’èƒŒæ™¯ã‚¹ãƒ¬ãƒƒãƒ‰ã§å®Ÿè¡Œ
registry_port = 8000
thread = threading.Thread(
    target=lambda: run_registry(registry, host="0.0.0.0", port=registry_port),
    daemon=True
)
thread.start()
time.sleep(1)  # ãƒ¬ã‚¸ã‚¹ãƒˆãƒªã®èµ·å‹•ã‚’å¾…ã¤

# ã‚µãƒ³ãƒ—ãƒ«ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®ä½œæˆ
agent_card = AgentCard(
    name="Weather Agent",
    description="Provides weather information",
    url="http://localhost:8001",
    version="1.0.0",
    capabilities={
        "weather_forecasting": True,
        "google_a2a_compatible": True  # Google A2A äº’æ›æ€§ã‚’æœ‰åŠ¹åŒ–
    }
)
agent = A2AServer(agent_card=agent_card)

# ç™ºè¦‹ã‚’æœ‰åŠ¹åŒ– - ã“ã‚Œã¯ãƒ¬ã‚¸ã‚¹ãƒˆãƒªã«ç™»éŒ²ã—ã¾ã™
registry_url = f"http://localhost:{registry_port}"
discovery_client = enable_discovery(agent, registry_url=registry_url)

# åˆ¥ã‚¹ãƒ¬ãƒƒãƒ‰ã§ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’å®Ÿè¡Œ
agent_thread = threading.Thread(
    target=lambda: run_server(agent, host="0.0.0.0", port=8001),
    daemon=True
)
agent_thread.start()
time.sleep(1)  # ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®èµ·å‹•ã‚’å¾…ã¤

# ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆç™ºè¦‹ç”¨ã®ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®ä½œæˆ
client = DiscoveryClient(agent_card=None)  # ç™ºè¦‹å°‚ç”¨ã«ã¯ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚«ãƒ¼ãƒ‰ã¯å¿…è¦ã‚ã‚Šã¾ã›ã‚“
client.add_registry(registry_url)

# ã™ã¹ã¦ã®ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’ç™ºè¦‹
agents = client.discover()
print(f"{len(agents)} å€‹ã®ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’ç™ºè¦‹ã—ã¾ã—ãŸ:")
for agent in agents:
    print(f"- {agent.name} ã¯ {agent.url} ã«ã‚ã‚Šã¾ã™")
    print(f"  èƒ½åŠ›: {agent.capabilities}")
```

## ğŸ“– ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ & è¨­è¨ˆåŸå‰‡

Python A2A ã¯ 3 ã¤ã®ã‚³ã‚¢è¨­è¨ˆåŸå‰‡ã«åŸºã¥ã„ã¦æ§‹ç¯‰ã•ã‚Œã¦ã„ã¾ã™:

1. **ãƒ—ãƒ­ãƒˆã‚³ãƒ«ç¬¬ä¸€**: A2A ãŠã‚ˆã³ MCP ãƒ—ãƒ­ãƒˆã‚³ãƒ«ä»•æ§˜ã«å³å¯†ã«å¾“ã£ã¦æœ€å¤§é™ã®ç›¸äº’é‹ç”¨æ€§ã‚’ç¢ºä¿

2. **ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«æ€§**: ã™ã¹ã¦ã®ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã¯çµ„ã¿åˆã‚ã›å¯èƒ½ã§ç½®ãæ›ãˆå¯èƒ½ã«è¨­è¨ˆã•ã‚Œã¦ã„ã¾ã™

3. **é€²åŒ–çš„å¼·åŒ–**: ç°¡å˜ã«å§‹ã‚ã€å¿…è¦ã«å¿œã˜ã¦è¤‡é›‘ã•ã‚’è¿½åŠ 

ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã¯ 8 ã¤ã®ä¸»è¦ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã‹ã‚‰æ§‹æˆã•ã‚Œã¦ã„ã¾ã™:

- **ãƒ¢ãƒ‡ãƒ«**: A2A ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã€ã‚¿ã‚¹ã‚¯ã€ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚«ãƒ¼ãƒ‰ã‚’è¡¨ã™ãƒ‡ãƒ¼ã‚¿æ§‹é€ 
- **ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ**: A2A ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã«ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’é€ä¿¡ã—ã€ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚’ç®¡ç†ã™ã‚‹ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆ
- **ã‚µãƒ¼ãƒãƒ¼**: A2A äº’æ›ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’æ§‹ç¯‰ã™ã‚‹ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆ
- **ç™ºè¦‹**: ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚¨ã‚³ã‚·ã‚¹ãƒ†ãƒ ã®ãƒ¬ã‚¸ã‚¹ãƒˆãƒªãŠã‚ˆã³ç™ºè¦‹ãƒ¡ã‚«ãƒ‹ã‚ºãƒ 
- **MCP**: Model Context Protocol ã‚µãƒ¼ãƒãƒ¼ãŠã‚ˆã³ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’å®Ÿè£…ã™ã‚‹ãƒ„ãƒ¼ãƒ«
- **LangChain**: LangChain çµ±åˆã®ãŸã‚ã®ãƒ–ãƒªãƒƒã‚¸ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆ
- **ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼**: è¤‡é›‘ãªã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆç›¸äº’ä½œç”¨ã‚’ã‚ªãƒ¼ã‚±ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã™ã‚‹ã‚¨ãƒ³ã‚¸ãƒ³
- **ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£**: ä¸€èˆ¬çš„ãªã‚¿ã‚¹ã‚¯ç”¨ã®ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•°
- **CLI**: ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã¨å¯¾è©±ã™ã‚‹ãŸã‚ã®ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹

## ğŸ—ºï¸ ç”¨ä¾‹

Python A2A ã¯ã€ã•ã¾ã–ã¾ãª AI ã‚·ã‚¹ãƒ†ãƒ ã®æ§‹ç¯‰ã«ä½¿ç”¨ã§ãã¾ã™:

### ç ”ç©¶ & é–‹ç™º

- **å®Ÿé¨“ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯**: åŒã˜ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ã‚’ç¶­æŒã—ãªãŒã‚‰ç•°ãªã‚‹ LLM ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã‚’ç°¡å˜ã«äº¤æ›
- **ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚¹ã‚¤ãƒ¼ãƒˆ**: æ¨™æº–åŒ–ã•ã‚ŒãŸã‚¿ã‚¹ã‚¯ã§ç•°ãªã‚‹ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå®Ÿè£…ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’æ¯”è¼ƒ
- **ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ç ”ç©¶ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆ**: ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ã‚’ä½¿ç”¨ã—ã¦å®Ÿæ™‚é–“ã®å‡ºåŠ›ã‚’æŒã¤å¿œç­”çš„ãªç ”ç©¶ãƒ„ãƒ¼ãƒ«ã‚’ä½œæˆ

### ã‚¨ãƒ³ã‚¿ãƒ¼ãƒ—ãƒ©ã‚¤ã‚º ã‚·ã‚¹ãƒ†ãƒ 

- **AI ã‚ªãƒ¼ã‚±ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³**: ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚’ä½¿ç”¨ã—ã¦ç•°ãªã‚‹éƒ¨é–€ã® AI ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’èª¿æ•´
- **ãƒ¬ã‚¬ã‚·ãƒ¼ã‚·ã‚¹ãƒ†ãƒ çµ±åˆ**: A2A ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ã§ãƒ¬ã‚¬ã‚·ãƒ¼ã‚·ã‚¹ãƒ†ãƒ ã‚’ãƒ©ãƒƒãƒ—ã—ã¦ AI ã¸ã®ã‚¢ã‚¯ã‚»ã‚¹ã‚’æä¾›
- **è¤‡é›‘ãªãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼**: ãƒãƒ«ãƒã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ãŠã‚ˆã³æ¡ä»¶åˆ†å²ã‚’ä½¿ç”¨ã—ãŸè¤‡é›‘ãªãƒ“ã‚¸ãƒã‚¹ãƒ—ãƒ­ã‚»ã‚¹ã®ä½œæˆ

### ã‚«ã‚¹ã‚¿ãƒãƒ¼ãƒ•ãƒ¬ãƒ³ãƒ‰ãƒªãƒ¼ãªã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³

- **ãƒãƒ«ãƒã‚¹ãƒ†ãƒ¼ã‚¸ ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆ**: å°‚é–€åˆ†é‡åˆ¥ã®ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã§è¤‡é›‘ãªãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚¯ã‚¨ãƒªã‚’ã‚µãƒ–ã‚¿ã‚¹ã‚¯ã«åˆ†å‰²
- **ãƒ„ãƒ¼ãƒ«ä½¿ç”¨ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ**: ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã€è¨ˆç®—ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãªã©ã« LLM ã‚’æ¥ç¶šã™ã‚‹ MCP ã‚’ä½¿ç”¨
- **ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒãƒ£ãƒƒãƒˆã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹**: ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å¿œç­”ã‚µãƒãƒ¼ãƒˆã§å¿œç­”çš„ãªãƒãƒ£ãƒƒãƒˆã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚’æ§‹ç¯‰

### æ•™è‚² & ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°

- **AI æ•™è‚²**: ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå”åŠ›ã®ãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ç”¨ã®æ•™è‚²ã‚·ã‚¹ãƒ†ãƒ ã®ä½œæˆ
- **ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ç’°å¢ƒ**: è¤‡æ•°ã®ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãŒç›¸äº’ä½œç”¨ã™ã‚‹ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ç’°å¢ƒã®æ§‹ç¯‰
- **æ•™è‚²ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼**: ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ãƒ«ãƒ¼ãƒ—ã‚’å‚™ãˆãŸã‚¹ãƒ†ãƒƒãƒ—ãƒã‚¤ã‚¹ãƒ†ãƒƒãƒ—ã®å­¦ç¿’ãƒ—ãƒ­ã‚»ã‚¹ã®è¨­è¨ˆ

## ğŸ› ï¸ å®Ÿä¸–ç•Œã®ä¾‹

[`examples/`](https://github.com/themanojdesai/python-a2a/tree/main/examples) ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«å®Ÿä¸–ç•Œã®ä¾‹ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚ã“ã‚Œã«ã¯ä»¥ä¸‹ãŒå«ã¾ã‚Œã¾ã™:

- ãƒãƒ«ãƒã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚«ã‚¹ã‚¿ãƒãƒ¼ã‚µãƒãƒ¼ãƒˆã‚·ã‚¹ãƒ†ãƒ 
- ãƒ„ãƒ¼ãƒ«ã‚¢ã‚¯ã‚»ã‚¹ä»˜ã LLM ãƒ‘ãƒ¯ãƒ¼ãƒ‰ç ”ç©¶ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆ
- å®Ÿæ™‚é–“ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å®Ÿè£…
- LangChain çµ±åˆä¾‹
- å„ç¨®ãƒ„ãƒ¼ãƒ«ç”¨ MCP ã‚µãƒ¼ãƒãƒ¼å®Ÿè£…
- ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ ã‚ªãƒ¼ã‚±ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ä¾‹
- ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ç®¡ç†

## ğŸ”„ é–¢é€£ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ

AI ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãŠã‚ˆã³ç›¸äº’é‹ç”¨æ€§ç©ºé–“ã®é–¢é€£ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ:

- [**Google A2A**](https://github.com/google/A2A) - å…¬å¼ Google A2A ãƒ—ãƒ­ãƒˆã‚³ãƒ«ä»•æ§˜
- [**LangChain**](https://github.com/langchain-ai/langchain) - LLM ã‚’ä½¿ç”¨ã—ãŸã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³æ§‹ç¯‰ã®ãŸã‚ã®ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯
- [**AutoGen**](https://github.com/microsoft/autogen) - Microsoft ã®ãƒãƒ«ãƒã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆä¼šè©±ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯
- [**CrewAI**](https://github.com/joaomdmoura/crewAI) - ãƒ­ãƒ¼ãƒ«ãƒ—ãƒ¬ã‚¤ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®ã‚ªãƒ¼ã‚±ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ç”¨ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯
- [**MCP**](https://github.com/contextco/mcp) - ãƒ„ãƒ¼ãƒ«ä½¿ç”¨ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®ãŸã‚ã® Model Context Protocol

## ğŸ‘¥ è²¢çŒ®è€…

ã™ã¹ã¦ã®è²¢çŒ®è€…ã«æ„Ÿè¬ã—ã¾ã™!

<a href="https://github.com/themanojdesai/python-a2a/graphs/contributors">
  <img src="https://contrib.rocks/image?repo=themanojdesai/python-a2a" />
</a>

è²¢çŒ®ã—ãŸã„å ´åˆã¯ã€[contributing guide](https://python-a2a.readthedocs.io/en/latest/contributing.html) ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚

## ğŸ¤ ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ & ã‚µãƒãƒ¼ãƒˆ

- **[GitHub Issues](https://github.com/themanojdesai/python-a2a/issues)**: ãƒã‚°ã‚’å ±å‘Šã¾ãŸã¯æ©Ÿèƒ½ã‚’ãƒªã‚¯ã‚¨ã‚¹ãƒˆ
- **[GitHub Discussions](https://github.com/themanojdesai/python-a2a/discussions)**: è³ªå•ã‚’ã—ãŸã‚Šã‚¢ã‚¤ãƒ‡ã‚¢ã‚’å…±æœ‰ã—ãŸã‚Š
- **[Contributing Guide](https://python-a2a.readthedocs.io/en/latest/contributing.html)**: ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã¸ã®è²¢çŒ®æ–¹æ³•ã‚’å­¦ã¶
- **[ReadTheDocs](https://python-a2a.readthedocs.io/en/latest/)**: ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã‚µã‚¤ãƒˆã‚’è¨ªå•

## ğŸ“ ã“ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®å¼•ç”¨

Python A2A ã‚’ç ”ç©¶ã¾ãŸã¯å­¦è¡“çš„ãªä½œæ¥­ã§ä½¿ç”¨ã™ã‚‹å ´åˆã¯ã€ä»¥ä¸‹ã®ã‚ˆã†ã«å¼•ç”¨ã—ã¦ãã ã•ã„:

```
@software{desai2025pythona2a,
  author = {Desai, Manoj},
  title = {Python A2A: A Comprehensive Implementation of the Agent-to-Agent Protocol},
  url = {https://github.com/themanojdesai/python-a2a},
  version = {0.5.0},
  year = {2025},
}
```

## â­ ã“ã®ãƒªãƒã‚¸ãƒˆãƒªã‚’ã‚¹ã‚¿ãƒ¼

ã“ã®ãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒå½¹ã«ç«‹ã¤å ´åˆã¯ã€GitHub ã§ã‚¹ã‚¿ãƒ¼ã‚’ä»˜ã‘ã¦ãã ã•ã„! ä»–ã®äººãŒãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚’ç™ºè¦‹ã—ã‚„ã™ãã—ã€ã•ã‚‰ãªã‚‹é–‹ç™ºã‚’ä¿ƒé€²ã™ã‚‹ã®ã«å½¹ç«‹ã¡ã¾ã™ã€‚

[![GitHub Repo stars](https://img.shields.io/github/stars/themanojdesai/python-a2a?style=social)](https://github.com/themanojdesai/python-a2a/stargazers)

### ã‚¹ã‚¿ãƒ¼å±¥æ­´

[![Star History Chart](https://api.star-history.com/svg?repos=themanojdesai/python-a2a&type=Date)](https://star-history.com/#themanojdesai/python-a2a&Date)

## ğŸ™ è¬è¾

- [Google A2A ãƒãƒ¼ãƒ ](https://github.com/google/A2A) ãŒ A2A ãƒ—ãƒ­ãƒˆã‚³ãƒ«ã‚’ä½œæˆã—ã¦ãã‚ŒãŸã“ã¨
- [Contextual AI ãƒãƒ¼ãƒ ](https://contextual.ai/) ãŒ Model Context Protocol ã‚’ä½œæˆã—ã¦ãã‚ŒãŸã“ã¨
- [LangChain ãƒãƒ¼ãƒ ](https://github.com/langchain-ai) ãŒå¼·åŠ›ãª LLM ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’ä½œæˆã—ã¦ãã‚ŒãŸã“ã¨
- ã™ã¹ã¦ã® [è²¢çŒ®è€…](https://github.com/themanojdesai/python-a2a/graphs/contributors) ãŒè²´é‡ãªå…¥åŠ›ã‚’ã—ã¦ãã‚ŒãŸã“ã¨

## ğŸ‘¨â€ğŸ’» è‘—è€…

**Manoj Desai**

- GitHub: [themanojdesai](https://github.com/themanojdesai)
- LinkedIn: [themanojdesai](https://www.linkedin.com/in/themanojdesai/)
- Medium: [@the_manoj_desai](https://medium.com/@the_manoj_desai)

## ğŸ“„ ãƒ©ã‚¤ã‚»ãƒ³ã‚¹

ã“ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã¯ MIT ãƒ©ã‚¤ã‚»ãƒ³ã‚¹ã®ä¸‹ã§ãƒ©ã‚¤ã‚»ãƒ³ã‚¹ã•ã‚Œã¦ã„ã¾ã™ - [LICENSE](LICENSE) ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‚ç…§ã—ã¦è©³ç´°ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚

---

Manoj Desai ã«ã‚ˆã£ã¦ â¤ï¸ ã§ä½œæˆ
