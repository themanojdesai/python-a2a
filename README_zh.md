# Python A2A

<div align="center">

[![PyPI version](https://img.shields.io/pypi/v/python-a2a.svg)](https://pypi.org/project/python-a2a/)
[![Python Versions](https://img.shields.io/pypi/pyversions/python-a2a.svg)](https://pypi.org/project/python-a2a/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![PyPI Downloads](https://static.pepy.tech/badge/python-a2a)](https://pepy.tech/project/python-a2a)
[![Documentation Status](https://readthedocs.org/projects/python-a2a/badge/?version=latest)](https://python-a2a.readthedocs.io/en/latest/?badge=latest)
[![Code style: black](https://img.shields.io/badge/code%20style-black-000000.svg)](https://github.com/psf/black)
[![Imports: isort](https://img.shields.io/badge/%20imports-isort-%231674b1?style=flat&labelColor=ef8336)](https://pycqa.github.io/isort/)
[![UV Compatible](https://img.shields.io/badge/UV-Compatible-5C63FF.svg)](https://github.com/astral-sh/uv)
[![GitHub stars](https://img.shields.io/github/stars/themanojdesai/python-a2a?style=social)](https://github.com/themanojdesai/python-a2a/stargazers)

  <p>
      <a href="README.md">English</a> | <a href="README_zh.md">ç®€ä½“ä¸­æ–‡</a> | <a href="README_ja.md">æ—¥æœ¬èª</a> | <a href="README_es.md">EspaÃ±ol</a> | <a href="README_de.md">Deutsch</a> | <a href="README_fr.md">FranÃ§ais</a>
      <!-- Add other languages here like: | <a href="README_de.md">Deutsch</a> -->
  </p>

**Google Agent-to-Agent (A2A) åè®®çš„å®˜æ–¹ Python å®ç°ï¼Œé›†æˆ Model Context Protocol (MCP)**

</div>

## ğŸŒŸ æ¦‚è¿°

Python A2A æ˜¯ä¸€ä¸ªå…¨é¢ä¸”é€‚ç”¨äºç”Ÿäº§ç¯å¢ƒçš„åº“ï¼Œç”¨äºå®ç° Google çš„ [Agent-to-Agent (A2A) åè®®](https://google.github.io/A2A/)ï¼Œå¹¶å®Œå…¨æ”¯æŒ [Model Context Protocol (MCP)](https://contextual.ai/introducing-mcp/)ã€‚å®ƒæä¾›äº†æ„å»ºå¯äº’æ“ä½œçš„ AI ä»£ç†ç”Ÿæ€ç³»ç»Ÿæ‰€éœ€çš„æ‰€æœ‰åŠŸèƒ½ï¼Œè¿™äº›ä»£ç†å¯ä»¥æ— ç¼åä½œä»¥è§£å†³å¤æ‚é—®é¢˜ã€‚

A2A åè®®ä¸º AI ä»£ç†ä¹‹é—´çš„äº¤äº’å»ºç«‹äº†æ ‡å‡†é€šä¿¡æ ¼å¼ï¼Œè€Œ MCP é€šè¿‡æä¾›æ ‡å‡†åŒ–çš„æ–¹æ³•æ‰©å±•äº†è¿™ä¸€åŠŸèƒ½ï¼Œä½¿ä»£ç†èƒ½å¤Ÿè®¿é—®å¤–éƒ¨å·¥å…·å’Œæ•°æ®æºã€‚Python A2A é€šè¿‡ç›´è§‚çš„ API ä½¿è¿™äº›åè®®æ˜“äºä½¿ç”¨ï¼Œå¼€å‘è€…å¯ä»¥ä½¿ç”¨è¿™äº› API æ„å»ºå¤æ‚çš„å¤šä»£ç†ç³»ç»Ÿã€‚

## ğŸ“‹ v0.5.X æ–°å¢åŠŸèƒ½

- **ä»£ç†å‘ç°**ï¼šå†…ç½®ä»£ç†æ³¨å†Œè¡¨å’Œå‘ç°åŠŸèƒ½ï¼Œå®Œå…¨å…¼å®¹ Google A2A åè®®
- **LangChain é›†æˆ**ï¼šä¸ LangChain çš„å·¥å…·å’Œä»£ç†æ— ç¼é›†æˆ
- **æ‰©å±•çš„å·¥å…·ç”Ÿæ€ç³»ç»Ÿ**ï¼šåœ¨ä»»ä½•ä»£ç†ä¸­ä½¿ç”¨ LangChain å’Œ MCP å·¥å…·
- **å¢å¼ºçš„ä»£ç†äº’æ“ä½œæ€§**ï¼šåœ¨ A2A ä»£ç†å’Œ LangChain ä»£ç†ä¹‹é—´è¿›è¡Œè½¬æ¢
- **æ··åˆå·¥ä½œæµå¼•æ“**ï¼šæ„å»ºç»“åˆä¸¤ç§ç”Ÿæ€ç³»ç»Ÿçš„å¤æ‚å·¥ä½œæµ
- **ç®€åŒ–ä»£ç†å¼€å‘**ï¼šå³æ—¶è®¿é—®æ•°åƒä¸ªé¢„æ„å»ºå·¥å…·
- **é«˜çº§æµæ¶æ„**ï¼šå¢å¼ºçš„ Server-Sent Events (SSE) æµã€æ›´å¥½çš„é”™è¯¯å¤„ç†å’Œå¼ºå¤§çš„å›é€€æœºåˆ¶
- **åŸºäºä»»åŠ¡çš„æµ**ï¼šæ–°çš„ `tasks_send_subscribe` æ–¹æ³•ç”¨äºå®æ—¶æµå¼ä»»åŠ¡æ›´æ–°
- **æµå¼æ•°æ®å— API**ï¼šæ”¹è¿›çš„ `StreamingChunk` ç±»ç”¨äºç»“æ„åŒ–æµå¼æ•°æ®å¤„ç†
- **å¤šç«¯ç‚¹æ”¯æŒ**ï¼šåœ¨å¤šä¸ªæµå¼ç«¯ç‚¹ä¹‹é—´è‡ªåŠ¨å‘ç°å’Œå›é€€

## ğŸ“‹ v0.4.X æ–°å¢åŠŸèƒ½

- **ä»£ç†ç½‘ç»œç³»ç»Ÿ**ï¼šä½¿ç”¨æ–°çš„ `AgentNetwork` ç±»ç®¡ç†å’Œå‘ç°å¤šä¸ªä»£ç†
- **å®æ—¶æµå¼å¤„ç†**ï¼šä½¿ç”¨ `StreamingClient` å®ç°å“åº”å¼ UI çš„æµå¼å“åº”
- **å·¥ä½œæµå¼•æ“**ï¼šä½¿ç”¨æ–°çš„æµç•… API å®šä¹‰å¤æ‚å¤šä»£ç†å·¥ä½œæµï¼Œæ”¯æŒæ¡ä»¶åˆ†æ”¯å’Œå¹¶è¡Œæ‰§è¡Œ
- **AI è·¯ç”±å™¨**ï¼šä½¿ç”¨ `AIAgentRouter` è‡ªåŠ¨å°†æŸ¥è¯¢è·¯ç”±åˆ°æœ€åˆé€‚çš„ä»£ç†
- **å‘½ä»¤è¡Œç•Œé¢**ï¼šé€šè¿‡æ–°çš„ CLI å·¥å…·ä»ç»ˆç«¯æ§åˆ¶ä»£ç†
- **å¢å¼ºçš„å¼‚æ­¥æ”¯æŒ**ï¼šåœ¨æ•´ä¸ªåº“ä¸­æ”¹è¿›äº† async/await æ”¯æŒ
- **æ–°çš„è¿æ¥é€‰é¡¹**ï¼šæ”¹è¿›äº†ä»£ç†é€šä¿¡çš„é”™è¯¯å¤„ç†å’Œé‡è¯•é€»è¾‘

## âœ¨ ä¸ºä»€ä¹ˆé€‰æ‹© Python A2Aï¼Ÿ

- **å®Œæ•´å®ç°**ï¼šå®Œå…¨å®ç°å®˜æ–¹ A2A è§„èŒƒï¼Œæ— ä»»ä½•å¦¥å
- **ä»£ç†å‘ç°**ï¼šå†…ç½®ä»£ç†æ³¨å†Œè¡¨å’Œå‘ç°åŠŸèƒ½ï¼Œç”¨äºæ„å»ºä»£ç†ç”Ÿæ€ç³»ç»Ÿ
- **MCP é›†æˆ**ï¼šå¯¹ Model Context Protocol çš„ä¸€æµæ”¯æŒï¼Œå®ç°å¼ºå¤§çš„å·¥å…·ä½¿ç”¨ä»£ç†
- **ä¼ä¸šçº§å°±ç»ª**ï¼šä¸ºç”Ÿäº§ç¯å¢ƒæ„å»ºï¼Œå…·æœ‰å¼ºå¤§çš„é”™è¯¯å¤„ç†å’ŒéªŒè¯åŠŸèƒ½
- **æ¡†æ¶æ— å…³**ï¼šä¸ä»»ä½• Python æ¡†æ¶å…¼å®¹ï¼ˆFlaskã€FastAPIã€Django ç­‰ï¼‰
- **LLM æä¾›å•†çµæ´»æ€§**ï¼šåŸç”Ÿé›†æˆ OpenAIã€Anthropicã€AWS Bedrock ç­‰
- **æœ€å°ä¾èµ–**ï¼šæ ¸å¿ƒåŠŸèƒ½ä»…ä¾èµ– `requests` åº“
- **å“è¶Šçš„å¼€å‘è€…ä½“éªŒ**ï¼šå…¨é¢çš„æ–‡æ¡£ã€ç±»å‹æç¤ºå’Œç¤ºä¾‹

## ğŸ“¦ å®‰è£…

### ä½¿ç”¨ pipï¼ˆä¼ ç»Ÿæ–¹å¼ï¼‰

å®‰è£…åŒ…å«æ‰€æœ‰ä¾èµ–é¡¹çš„åŸºç¡€åŒ…ï¼š

```bash
pip install python-a2a  # åŒ…å« LangChainã€MCP å’Œå…¶ä»–é›†æˆ
```

æˆ–æ ¹æ®éœ€æ±‚å®‰è£…ç‰¹å®šç»„ä»¶ï¼š

```bash
# å®‰è£… Flask æœåŠ¡å™¨æ”¯æŒ
pip install "python-a2a[server]"

# å®‰è£… OpenAI é›†æˆ
pip install "python-a2a[openai]"

# å®‰è£… Anthropic Claude é›†æˆ
pip install "python-a2a[anthropic]"

# å®‰è£… AWS-Bedrock é›†æˆ
pip install "python-a2a[bedrock]"

# å®‰è£… MCP æ”¯æŒï¼ˆModel Context Protocolï¼‰
pip install "python-a2a[mcp]"

# å®‰è£…æ‰€æœ‰å¯é€‰ä¾èµ–é¡¹
pip install "python-a2a[all]"
```

### ä½¿ç”¨ UVï¼ˆæ¨èï¼‰

[UV](https://github.com/astral-sh/uv) æ˜¯ä¸€ä¸ªç°ä»£çš„ Python åŒ…ç®¡ç†å·¥å…·ï¼Œæ¯” pip æ›´å¿«æ›´å¯é ã€‚ä½¿ç”¨ UV å®‰è£…ï¼š

```bash
# å¦‚æœå°šæœªå®‰è£… UVï¼Œè¯·å…ˆå®‰è£…
curl -LsSf https://astral.sh/uv/install.sh | sh

# å®‰è£…åŸºç¡€åŒ…
uv install python-a2a
```

### å¼€å‘å®‰è£…

å¼€å‘ç¯å¢ƒæ¨èä½¿ç”¨ UV ä»¥è·å¾—æ›´ä½³æ€§èƒ½ï¼š

```bash
# å…‹éš†ä»“åº“
git clone https://github.com/themanojdesai/python-a2a.git
cd python-a2a

# åˆ›å»ºè™šæ‹Ÿç¯å¢ƒå¹¶å®‰è£…å¼€å‘ä¾èµ–é¡¹
uv venv
source .venv/bin/activate  # Windows: .venv\Scripts\activate
uv pip install -e ".[dev]"
```

> ğŸ’¡ **æç¤º**ï¼šç‚¹å‡»ä»£ç å—å¯å¤åˆ¶åˆ°å‰ªè´´æ¿

## ğŸš€ å¿«é€Ÿå…¥é—¨ç¤ºä¾‹

### 1. åˆ›å»ºå¸¦æœ‰æŠ€èƒ½çš„ç®€å• A2A ä»£ç†

```python
from python_a2a import A2AServer, skill, agent, run_server, TaskStatus, TaskState

@agent(
    name="Weather Agent",
    description="Provides weather information",
    version="1.0.0"
)
class WeatherAgent(A2AServer):
    
    @skill(
        name="Get Weather",
        description="Get current weather for a location",
        tags=["weather", "forecast"]
    )
    def get_weather(self, location):
        """Get weather for a location."""
        # Mock implementation
        return f"It's sunny and 75Â°F in {location}"
    
    def handle_task(self, task):
        # Extract location from message
        message_data = task.message or {}
        content = message_data.get("content", {})
        text = content.get("text", "") if isinstance(content, dict) else ""
        
        if "weather" in text.lower() and "in" in text.lower():
            location = text.split("in", 1)[1].strip().rstrip("?.")
            
            # Get weather and create response
            weather_text = self.get_weather(location)
            task.artifacts = [{
                "parts": [{"type": "text", "text": weather_text}]
            }]
            task.status = TaskStatus(state=TaskState.COMPLETED)
        else:
            task.status = TaskStatus(
                state=TaskState.INPUT_REQUIRED,
                message={"role": "agent", "content": {"type": "text", 
                         "text": "Please ask about weather in a specific location."}}
            )
        return task

# Run the server
if __name__ == "__main__":
    agent = WeatherAgent()
    run_server(agent, port=5000)
```

### 2. æ„å»ºåŒ…å«å¤šä¸ªä»£ç†çš„ä»£ç†ç½‘ç»œ

```python
from python_a2a import AgentNetwork, A2AClient, AIAgentRouter

# åˆ›å»ºä»£ç†ç½‘ç»œ
network = AgentNetwork(name="Travel Assistant Network")

# æ·»åŠ ä»£ç†åˆ°ç½‘ç»œ
network.add("weather", "http://localhost:5001")
network.add("hotels", "http://localhost:5002")
network.add("attractions", "http://localhost:5003")

# åˆ›å»ºè·¯ç”±å™¨ä»¥æ™ºèƒ½åœ°å°†æŸ¥è¯¢å®šå‘åˆ°æœ€ä½³ä»£ç†
router = AIAgentRouter(
    llm_client=A2AClient("http://localhost:5000/openai"),  # ç”¨äºè·¯ç”±å†³ç­–çš„ LLM
    agent_network=network
)

# å°†æŸ¥è¯¢è·¯ç”±åˆ°é€‚å½“çš„ä»£ç†
agent_name, confidence = router.route_query("What's the weather like in Paris?")
print(f"Routing to {agent_name} with {confidence:.2f} confidence")

# è·å–é€‰å®šçš„ä»£ç†å¹¶æé—®
agent = network.get_agent(agent_name)
response = agent.ask("What's the weather like in Paris?")
print(f"Response: {response}")

# åˆ—å‡ºæ‰€æœ‰å¯ç”¨ä»£ç†
print("\nAvailable Agents:")
for agent_info in network.list_agents():
    print(f"- {agent_info['name']}: {agent_info['description']}")
```

### å®æ—¶æµå¼å¤„ç†

é€šè¿‡å…¨é¢çš„æµå¼æ”¯æŒä»ä»£ç†è·å–å®æ—¶å“åº”ï¼š

```python
import asyncio
from python_a2a import StreamingClient, Message, TextContent, MessageRole

async def main():
    client = StreamingClient("http://localhost:5000")
    
    # åˆ›å»ºå¸¦æœ‰å¿…éœ€ role å‚æ•°çš„æ¶ˆæ¯
    message = Message(
        content=TextContent(text="Tell me about A2A streaming"),
        role=MessageRole.USER
    )
    
    # æµå¼å¤„ç†å“åº”å¹¶å®æ—¶å¤„ç†æ•°æ®å—
    try:
        async for chunk in client.stream_response(message):
            # å¤„ç†ä¸åŒæ ¼å¼çš„æ•°æ®å—ï¼ˆå­—ç¬¦ä¸²æˆ–å­—å…¸ï¼‰
            if isinstance(chunk, dict):
                if "content" in chunk:
                    print(chunk["content"], end="", flush=True)
                elif "text" in chunk:
                    print(chunk["text"], end="", flush=True)
                else:
                    print(str(chunk), end="", flush=True)
            else:
                print(str(chunk), end="", flush=True)
    except Exception as e:
        print(f"Streaming error: {e}")
```

æŸ¥çœ‹ `examples/streaming/` ç›®å½•ä¸­çš„å®Œæ•´æµå¼ç¤ºä¾‹ï¼š

- **basic_streaming.py**ï¼šæœ€å°åŒ–æµå¼å®ç°ï¼ˆä»è¿™é‡Œå¼€å§‹ï¼ï¼‰
- **01_basic_streaming.py**ï¼šæµå¼åŸºç¡€çš„å…¨é¢ä»‹ç»
- **02_advanced_streaming.py**ï¼šä½¿ç”¨ä¸åŒåˆ†å—ç­–ç•¥çš„é«˜çº§æµå¼å¤„ç†
- **03_streaming_llm_integration.py**ï¼šå°†æµå¼å¤„ç†ä¸ LLM æä¾›å•†é›†æˆ
- **04_task_based_streaming.py**ï¼šåŸºäºä»»åŠ¡çš„æµå¼å¤„ç†ä¸è¿›åº¦è·Ÿè¸ª
- **05_streaming_ui_integration.py**ï¼šæµå¼ UI é›†æˆï¼ˆCLI å’Œ Webï¼‰
- **06_distributed_streaming.py**ï¼šåˆ†å¸ƒå¼æµå¼æ¶æ„

### 3. å·¥ä½œæµå¼•æ“

æ–°çš„å·¥ä½œæµå¼•æ“å…è®¸æ‚¨å®šä¹‰å¤æ‚ä»£ç†äº¤äº’ï¼š

```python
from python_a2a import AgentNetwork, Flow
import asyncio

async def main():
    # è®¾ç½®ä»£ç†ç½‘ç»œ
    network = AgentNetwork()
    network.add("research", "http://localhost:5001")
    network.add("summarizer", "http://localhost:5002")
    network.add("factchecker", "http://localhost:5003")
    
    # å®šä¹‰ç ”ç©¶æŠ¥å‘Šç”Ÿæˆå·¥ä½œæµ
    flow = Flow(agent_network=network, name="Research Report Workflow")
    
    # é¦–å…ˆæ”¶é›†åˆå§‹ç ”ç©¶
    flow.ask("research", "Research the latest developments in {topic}")
    
    # ç„¶åå¹¶è¡Œå¤„ç†ç»“æœ
    parallel_results = (flow.parallel()
        # åˆ†æ”¯ 1ï¼šåˆ›å»ºæ‘˜è¦
        .ask("summarizer", "Summarize this research: {latest_result}")
        # åˆ†æ”¯ 2ï¼šéªŒè¯å…³é”®äº‹å®
        .branch()
        .ask("factchecker", "Verify these key facts: {latest_result}")
        # ç»“æŸå¹¶è¡Œå¤„ç†å¹¶æ”¶é›†ç»“æœ
        .end_parallel(max_concurrency=2))
    
    # æ ¹æ®éªŒè¯ç»“æœæå–è§è§£
    flow.execute_function(
        lambda results, context: f"Summary: {results['1']}\nVerified Facts: {results['2']}",
        parallel_results
    )
    
    # æ‰§è¡Œå·¥ä½œæµ
    result = await flow.run({
        "topic": "quantum computing advancements in the last year"
    })
    
    print(result)

if __name__ == "__main__":
    asyncio.run(main())
```

### 4. AI é©±åŠ¨çš„è·¯ç”±å™¨

æ™ºèƒ½è·¯ç”±ä»¥é€‰æ‹©æ¯ä¸ªæŸ¥è¯¢çš„æœ€ä½³ä»£ç†ï¼š

```python
from python_a2a import AgentNetwork, AIAgentRouter, A2AClient
import asyncio

async def main():
    # åˆ›å»ºå¸¦æœ‰ä¸“ç”¨ä»£ç†çš„ç½‘ç»œ
    network = AgentNetwork()
    network.add("math", "http://localhost:5001")
    network.add("history", "http://localhost:5002")
    network.add("science", "http://localhost:5003")
    network.add("literature", "http://localhost:5004")
    
    # åˆ›å»ºä½¿ç”¨ LLM è¿›è¡Œå†³ç­–çš„è·¯ç”±å™¨
    router = AIAgentRouter(
        llm_client=A2AClient("http://localhost:5000/openai"),
        agent_network=network
    )
    
    # è¦è·¯ç”±çš„ç¤ºä¾‹æŸ¥è¯¢
    queries = [
        "What is the formula for the area of a circle?",
        "Who wrote The Great Gatsby?",
        "When did World War II end?",
        "How does photosynthesis work?",
        "What are Newton's laws of motion?"
    ]
    
    # å°†æ¯ä¸ªæŸ¥è¯¢è·¯ç”±åˆ°æœ€ä½³ä»£ç†
    for query in queries:
        agent_name, confidence = router.route_query(query)
        agent = network.get_agent(agent_name)
        
        print(f"Query: {query}")
        print(f"Routed to: {agent_name} (confidence: {confidence:.2f})")
        
        # ä»é€‰å®šä»£ç†è·å–å“åº”
        response = agent.ask(query)
        print(f"Response: {response[:100]}...\n")

if __name__ == "__main__":
    asyncio.run(main())
```

### 5. å®šä¹‰åŒ…å«å¤šä¸ªä»£ç†çš„å¤æ‚å·¥ä½œæµ

```python
from python_a2a import AgentNetwork, Flow, AIAgentRouter
import asyncio

async def main():
    # åˆ›å»ºä»£ç†ç½‘ç»œ
    network = AgentNetwork()
    network.add("weather", "http://localhost:5001")
    network.add("recommendations", "http://localhost:5002")
    network.add("booking", "http://localhost:5003")
    
    # åˆ›å»ºè·¯ç”±å™¨
    router = AIAgentRouter(
        llm_client=network.get_agent("weather"),  # ä½¿ç”¨ä¸€ä¸ªä»£ç†ä½œä¸º LLM è¿›è¡Œè·¯ç”±
        agent_network=network
    )
    
    # å®šä¹‰å¸¦æœ‰æ¡ä»¶é€»è¾‘çš„å·¥ä½œæµ
    flow = Flow(agent_network=network, router=router, name="Travel Planning Workflow")
    
    # é¦–å…ˆè·å–å¤©æ°”
    flow.ask("weather", "What's the weather in {destination}?")
    
    # æ ¹æ®å¤©æ°”æ¡ä»¶åˆ†æ”¯
    flow.if_contains("sunny")
    
    # å¦‚æœæ™´æœ—ï¼Œæ¨èæˆ·å¤–æ´»åŠ¨
    flow.ask("recommendations", "Recommend outdoor activities in {destination}")
    
    # ç»“æŸæ¡ä»¶å¹¶æ·»åŠ  else åˆ†æ”¯
    flow.else_branch()
    
    # å¦‚æœä¸æ™´æœ—ï¼Œæ¨èå®¤å†…æ´»åŠ¨
    flow.ask("recommendations", "Recommend indoor activities in {destination}")
    
    # ç»“æŸ if-else å—
    flow.end_if()
    
    # æ·»åŠ å¹¶è¡Œå¤„ç†æ­¥éª¤
    (flow.parallel()
        .ask("booking", "Find hotels in {destination}")
        .branch()
        .ask("booking", "Find restaurants in {destination}")
        .end_parallel())
    
    # ä½¿ç”¨åˆå§‹ä¸Šä¸‹æ–‡æ‰§è¡Œå·¥ä½œæµ
    result = await flow.run({
        "destination": "Paris",
        "travel_dates": "June 12-20"
    })
    
    print("Workflow result:")
    print(result)

if __name__ == "__main__":
    asyncio.run(main())
```

### 6. ä½¿ç”¨å‘½ä»¤è¡Œç•Œé¢

```bash
# å‘ä»£ç†å‘é€æ¶ˆæ¯
a2a send http://localhost:5000 "What is artificial intelligence?"

# å®æ—¶æµå¼å“åº”
a2a stream http://localhost:5000 "Generate a step-by-step tutorial for making pasta"

# å¯åŠ¨ OpenAI é©±åŠ¨çš„ A2A æœåŠ¡å™¨
a2a openai --model gpt-4 --system-prompt "You are a helpful coding assistant"

# å¯åŠ¨ Anthropic é©±åŠ¨çš„ A2A æœåŠ¡å™¨
a2a anthropic --model claude-3-opus-20240229 --system-prompt "You are a friendly AI teacher"

# å¯åŠ¨å¸¦æœ‰å·¥å…·çš„ MCP æœåŠ¡å™¨
a2a mcp-serve --name "Data Analysis MCP" --port 5001 --script analysis_tools.py

# å¯åŠ¨å¯ç”¨ MCP çš„ A2A ä»£ç†
a2a mcp-agent --servers data=http://localhost:5001 calc=http://localhost:5002

# ç›´æ¥è°ƒç”¨ MCP å·¥å…·
a2a mcp-call http://localhost:5001 analyze_csv --params file=data.csv columns=price,date

# ç®¡ç†ä»£ç†ç½‘ç»œ
a2a network --add weather=http://localhost:5001 travel=http://localhost:5002 --save network.json

# ä»è„šæœ¬è¿è¡Œå·¥ä½œæµ
a2a workflow --script research_workflow.py --context initial_data.json
```

## ğŸ”„ LangChain é›†æˆï¼ˆv0.5.X æ–°å¢ï¼‰

Python A2A åŒ…å«å†…ç½®çš„ LangChain é›†æˆï¼Œä½¿æ‚¨å¯ä»¥è½»æ¾ç»“åˆä¸¤ç§ç”Ÿæ€ç³»ç»Ÿçš„æœ€ä½³åŠŸèƒ½ï¼š

### 1. å°† MCP å·¥å…·è½¬æ¢ä¸º LangChain

```python
from python_a2a.mcp import FastMCP, text_response
from python_a2a.langchain import to_langchain_tool

# åˆ›å»ºå¸¦æœ‰å·¥å…·çš„ MCP æœåŠ¡å™¨
mcp_server = FastMCP(name="Basic Tools", description="Simple utility tools")

@mcp_server.tool(
    name="calculator",
    description="Calculate a mathematical expression"
)
def calculator(input):
    """Simple calculator that evaluates an expression."""
    try:
        result = eval(input)
        return text_response(f"Result: {result}")
    except Exception as e:
        return text_response(f"Error: {e}")

# å¯åŠ¨æœåŠ¡å™¨
import threading, time
def run_server(server, port):
    server.run(host="0.0.0.0", port=port)
server_thread = threading.Thread(target=run_server, args=(mcp_server, 5000), daemon=True)
server_thread.start()
time.sleep(2)  # å…è®¸æœåŠ¡å™¨å¯åŠ¨

# å°† MCP å·¥å…·è½¬æ¢ä¸º LangChain
calculator_tool = to_langchain_tool("http://localhost:5000", "calculator")

# åœ¨ LangChain ä¸­ä½¿ç”¨å·¥å…·
result = calculator_tool.run("5 * 9 + 3")
print(f"Result: {result}")
```

### 2. å°† LangChain å·¥å…·è½¬æ¢ä¸º MCP æœåŠ¡å™¨

```python
from langchain.tools import Tool
from langchain_core.tools import BaseTool
from python_a2a.langchain import to_mcp_server

# åˆ›å»º LangChain å·¥å…·
def calculator(expression: str) -> str:
    """Evaluate a mathematical expression"""
    try:
        result = eval(expression)
        return f"Result: {expression} = {result}"
    except Exception as e:
        return f"Error: {e}"

calculator_tool = Tool(
    name="calculator",
    description="Evaluate a mathematical expression",
    func=calculator
)

# è½¬æ¢ä¸º MCP æœåŠ¡å™¨
mcp_server = to_mcp_server(calculator_tool)

# è¿è¡ŒæœåŠ¡å™¨
mcp_server.run(port=5000)
```

### 3. å°† LangChain ç»„ä»¶è½¬æ¢ä¸º A2A æœåŠ¡å™¨

```python
from langchain_openai import ChatOpenAI
from langchain_core.output_parsers import StrOutputParser
from langchain_core.prompts import PromptTemplate
from python_a2a import A2AClient, run_server
from python_a2a.langchain import to_a2a_server

# åˆ›å»º LangChain LLM
llm = ChatOpenAI(model="gpt-3.5-turbo", temperature=0)

# è½¬æ¢ä¸º A2A æœåŠ¡å™¨
llm_server = to_a2a_server(llm)

# åˆ›å»ºç®€å•é“¾
template = "You are a helpful travel guide.\n\nQuestion: {query}\n\nAnswer:"
prompt = PromptTemplate.from_template(template)
travel_chain = prompt | llm | StrOutputParser()

# è½¬æ¢ä¸º A2A æœåŠ¡å™¨
travel_server = to_a2a_server(travel_chain)

# åœ¨åå°çº¿ç¨‹ä¸­è¿è¡ŒæœåŠ¡å™¨
import threading
llm_thread = threading.Thread(
    target=lambda: run_server(llm_server, port=5001),
    daemon=True
)
llm_thread.start()

travel_thread = threading.Thread(
    target=lambda: run_server(travel_server, port=5002),
    daemon=True
)
travel_thread.start()

# æµ‹è¯•æœåŠ¡å™¨
llm_client = A2AClient("http://localhost:5001")
travel_client = A2AClient("http://localhost:5002")

llm_result = llm_client.ask("What is the capital of France?")
travel_result = travel_client.ask('{"query": "What are some must-see attractions in Paris?"}')
```

LangChain ä¼šè‡ªåŠ¨ä½œä¸ºä¾èµ–é¡¹å®‰è£…ï¼Œå› æ­¤ä¸€åˆ‡å¼€ç®±å³ç”¨ï¼š

```bash
pip install python-a2a
# å®Œæˆï¼LangChain ä¼šè‡ªåŠ¨åŒ…å«
```

## ğŸ§© æ ¸å¿ƒåŠŸèƒ½

### ä»£ç†ç½‘ç»œ

Python A2A ç°åœ¨åŒ…å«ä¸€ä¸ªå¼ºå¤§çš„ä»£ç†ç®¡ç†ç³»ç»Ÿï¼š

```python
from python_a2a import AgentNetwork, A2AClient

# åˆ›å»ºä»£ç†ç½‘ç»œ
network = AgentNetwork(name="Medical Assistant Network")

# ä»¥ä¸åŒæ–¹å¼æ·»åŠ ä»£ç†
network.add("diagnosis", "http://localhost:5001")  # ä» URL æ·»åŠ 
network.add("medications", A2AClient("http://localhost:5002"))  # ä»å®¢æˆ·ç«¯å®ä¾‹æ·»åŠ 

# ä» URL åˆ—è¡¨å‘ç°ä»£ç†
discovered_count = network.discover_agents([
    "http://localhost:5003",
    "http://localhost:5004",
    "http://localhost:5005"
])
print(f"Discovered {discovered_count} new agents")

# åˆ—å‡ºç½‘ç»œä¸­çš„æ‰€æœ‰ä»£ç†
for agent_info in network.list_agents():
    print(f"Agent: {agent_info['name']}")
    print(f"URL: {agent_info['url']}")
    if 'description' in agent_info:
        print(f"Description: {agent_info['description']}")
    print()

# è·å–ç‰¹å®šä»£ç†
agent = network.get_agent("diagnosis")
response = agent.ask("What are the symptoms of the flu?")
```

### 7. ä»£ç†å‘ç°å’Œæ³¨å†Œè¡¨

```python
from python_a2a import AgentCard, A2AServer, run_server
from python_a2a.discovery import AgentRegistry, run_registry, enable_discovery, DiscoveryClient
import threading
import time

# åˆ›å»ºæ³¨å†Œè¡¨æœåŠ¡å™¨
registry = AgentRegistry(
    name="A2A Registry Server",
    description="Central registry for agent discovery"
)

# åœ¨åå°çº¿ç¨‹ä¸­è¿è¡Œæ³¨å†Œè¡¨
registry_port = 8000
thread = threading.Thread(
    target=lambda: run_registry(registry, host="0.0.0.0", port=registry_port),
    daemon=True
)
thread.start()
time.sleep(1)  # ç­‰å¾…æ³¨å†Œè¡¨å¯åŠ¨

# åˆ›å»ºç¤ºä¾‹ä»£ç†
agent_card = AgentCard(
    name="Weather Agent",
    description="Provides weather information",
    url="http://localhost:8001",
    version="1.0.0",
    capabilities={
        "weather_forecasting": True,
        "google_a2a_compatible": True  # å¯ç”¨ Google A2A å…¼å®¹æ€§
    }
)
agent = A2AServer(agent_card=agent_card)

# å¯ç”¨å‘ç° - è¿™ä¼šå‘æ³¨å†Œè¡¨æ³¨å†Œ
registry_url = f"http://localhost:{registry_port}"
discovery_client = enable_discovery(agent, registry_url=registry_url)

# åœ¨å•ç‹¬çº¿ç¨‹ä¸­è¿è¡Œä»£ç†
agent_thread = threading.Thread(
    target=lambda: run_server(agent, host="0.0.0.0", port=8001),
    daemon=True
)
agent_thread.start()
time.sleep(1)  # ç­‰å¾…ä»£ç†å¯åŠ¨

# åˆ›å»ºç”¨äºå‘ç°ä»£ç†çš„å®¢æˆ·ç«¯
client = DiscoveryClient(agent_card=None)  # ä»…å‘ç°ä¸éœ€è¦ä»£ç†å¡
client.add_registry(registry_url)

# å‘ç°æ‰€æœ‰ä»£ç†
agents = client.discover()
print(f"Discovered {len(agents)} agents:")
for agent in agents:
    print(f"- {agent.name} at {agent.url}")
    print(f"  Capabilities: {agent.capabilities}")
```

## ğŸ“– æ¶æ„ä¸è®¾è®¡åŸåˆ™

Python A2A åŸºäºä¸‰ä¸ªæ ¸å¿ƒè®¾è®¡åŸåˆ™ï¼š

1. **åè®®ä¼˜å…ˆ**ï¼šä¸¥æ ¼éµå®ˆ A2A å’Œ MCP åè®®è§„èŒƒä»¥å®ç°æœ€å¤§äº’æ“ä½œæ€§
2. **æ¨¡å—åŒ–**ï¼šæ‰€æœ‰ç»„ä»¶å‡å¯ç»„åˆå’Œæ›¿æ¢
3. **æ¸è¿›å¢å¼º**ï¼šä»ç®€å•å¼€å§‹ï¼Œä»…åœ¨éœ€è¦æ—¶å¢åŠ å¤æ‚æ€§

æ¶æ„åŒ…å«å…«ä¸ªä¸»è¦ç»„ä»¶ï¼š

- **Models**ï¼šè¡¨ç¤º A2A æ¶ˆæ¯ã€ä»»åŠ¡å’Œä»£ç†å¡çš„æ•°æ®ç»“æ„
- **Client**ï¼šç”¨äºå‘ A2A ä»£ç†å‘é€æ¶ˆæ¯å’Œç®¡ç†ä»£ç†ç½‘ç»œçš„ç»„ä»¶
- **Server**ï¼šç”¨äºæ„å»º A2A å…¼å®¹ä»£ç†çš„ç»„ä»¶
- **Discovery**ï¼šä»£ç†ç”Ÿæ€ç³»ç»Ÿçš„æ³¨å†Œè¡¨å’Œå‘ç°æœºåˆ¶
- **MCP**ï¼šå®ç° Model Context Protocol æœåŠ¡å™¨å’Œå®¢æˆ·ç«¯çš„å·¥å…·
- **LangChain**ï¼šLangChain é›†æˆçš„æ¡¥æ¥ç»„ä»¶
- **Workflow**ï¼šç”¨äºåè°ƒå¤æ‚ä»£ç†äº¤äº’çš„å·¥ä½œæµå¼•æ“
- **Utils**ï¼šå¸¸ç”¨ä»»åŠ¡çš„è¾…åŠ©å‡½æ•°
- **CLI**ï¼šä¸ä»£ç†äº¤äº’çš„å‘½ä»¤è¡Œç•Œé¢

## ğŸ—ºï¸ ç”¨ä¾‹

Python A2A å¯ç”¨äºæ„å»ºå„ç§ AI ç³»ç»Ÿï¼š

### ç ”ç©¶ä¸å¼€å‘

- **å®éªŒæ¡†æ¶**ï¼šåœ¨ä¿æŒç›¸åŒä»£ç†æ¥å£çš„åŒæ—¶è½»æ¾æ›¿æ¢ä¸åŒçš„ LLM åç«¯
- **åŸºå‡†å¥—ä»¶**ï¼šåœ¨æ ‡å‡†åŒ–ä»»åŠ¡ä¸Šæ¯”è¾ƒä¸åŒä»£ç†å®ç°çš„æ€§èƒ½
- **æµå¼ç ”ç©¶åŠ©æ‰‹**ï¼šä½¿ç”¨æµå¼å¤„ç†åˆ›å»ºå“åº”å¼ç ”ç©¶å·¥å…·

### ä¼ä¸šç³»ç»Ÿ

- **AI åè°ƒ**ï¼šä½¿ç”¨ä»£ç†ç½‘ç»œåè°ƒä¸åŒéƒ¨é—¨çš„å¤šä¸ª AI ä»£ç†
- **é—ç•™ç³»ç»Ÿé›†æˆ**ï¼šé€šè¿‡ A2A æ¥å£åŒ…è£…é—ç•™ç³»ç»Ÿä»¥å®ç° AI è®¿é—®
- **Workflow**ï¼šç”¨äºåè°ƒå¤æ‚ä»£ç†äº¤äº’çš„å·¥ä½œæµå¼•æ“
- **Utils**ï¼šå¸¸ç”¨ä»»åŠ¡çš„è¾…åŠ©å‡½æ•°
- **CLI**ï¼šä¸ä»£ç†äº¤äº’çš„å‘½ä»¤è¡Œç•Œé¢

## ğŸ—ºï¸ ç”¨ä¾‹

Python A2A å¯ç”¨äºæ„å»ºå„ç§ AI ç³»ç»Ÿï¼š

### ç ”ç©¶ä¸å¼€å‘

- **å®éªŒæ¡†æ¶**ï¼šåœ¨ä¿æŒç›¸åŒä»£ç†æ¥å£çš„åŒæ—¶è½»æ¾åˆ‡æ¢ä¸åŒçš„ LLM åç«¯
- **åŸºå‡†å¥—ä»¶**ï¼šåœ¨æ ‡å‡†åŒ–ä»»åŠ¡ä¸Šæ¯”è¾ƒä¸åŒä»£ç†å®ç°çš„æ€§èƒ½
- **æµå¼ç ”ç©¶åŠ©æ‰‹**ï¼šä½¿ç”¨æµå¼ä¼ è¾“åˆ›å»ºå…·æœ‰å®æ—¶è¾“å‡ºçš„ç ”ç©¶å·¥å…·

### ä¼ä¸šç³»ç»Ÿ

- **AI åè°ƒ**ï¼šä½¿ç”¨ä»£ç†ç½‘ç»œè·¨ä¸åŒéƒ¨é—¨åè°ƒå¤šä¸ª AI ä»£ç†
- **é—ç•™ç³»ç»Ÿé›†æˆ**ï¼šä½¿ç”¨ A2A æ¥å£åŒ…è£…é—ç•™ç³»ç»Ÿä»¥å®ç° AI è®¿é—®
- **å¤æ‚å·¥ä½œæµ**ï¼šä½¿ç”¨å¤šä»£ç†å·¥ä½œæµå’Œæ¡ä»¶åˆ†æ”¯åˆ›å»ºå¤æ‚ä¸šåŠ¡æµç¨‹

### é¢å‘å®¢æˆ·çš„åº”ç”¨

- **å¤šé˜¶æ®µåŠ©æ‰‹**ï¼šå°†å¤æ‚ç”¨æˆ·æŸ¥è¯¢åˆ†è§£ä¸ºç”±ä¸“ç”¨ä»£ç†å¤„ç†çš„å­ä»»åŠ¡
- **å·¥å…·ä½¿ç”¨ä»£ç†**ï¼šä½¿ç”¨ MCP å°† LLM è¿æ¥åˆ°æ•°æ®åº“ä»£ç†ã€è®¡ç®—ä»£ç†ç­‰
- **å®æ—¶èŠå¤©ç•Œé¢**ï¼šæ„å»ºæ”¯æŒæµå¼å“åº”çš„å“åº”å¼èŠå¤©åº”ç”¨

### æ•™è‚²ä¸åŸ¹è®­

- **AI æ•™è‚²**ï¼šåˆ›å»ºå±•ç¤ºä»£ç†åä½œçš„æ•™è‚²ç³»ç»Ÿ
- **æ¨¡æ‹Ÿç¯å¢ƒ**ï¼šæ„å»ºå¤šä¸ªä»£ç†äº¤äº’çš„æ¨¡æ‹Ÿç¯å¢ƒ
- **æ•™è‚²å·¥ä½œæµ**ï¼šè®¾è®¡å¸¦åé¦ˆå¾ªç¯çš„åˆ†æ­¥å­¦ä¹ æµç¨‹

## ğŸ› ï¸ å®é™…åº”ç”¨ç¤ºä¾‹

æŸ¥çœ‹ [`examples/`](https://github.com/themanojdesai/python-a2a/tree/main/examples) ç›®å½•ä¸­çš„å®é™…åº”ç”¨ç¤ºä¾‹ï¼ŒåŒ…æ‹¬ï¼š

- å¤šä»£ç†å®¢æˆ·æ”¯æŒç³»ç»Ÿ
- å¸¦å·¥å…·è®¿é—®çš„ LLM é©±åŠ¨ç ”ç©¶åŠ©æ‰‹
- å®æ—¶æµå¼ä¼ è¾“å®ç°
- LangChain é›†æˆç¤ºä¾‹
- å„ç§å·¥å…·çš„ MCP æœåŠ¡å™¨å®ç°
- å·¥ä½œæµåè°ƒç¤ºä¾‹
- ä»£ç†ç½‘ç»œç®¡ç†

## ğŸ”„ ç›¸å…³é¡¹ç›®

AI ä»£ç†å’Œäº’æ“ä½œæ€§é¢†åŸŸçš„ç›¸å…³é¡¹ç›®ï¼š

- [**Google A2A**](https://github.com/google/A2A) - å®˜æ–¹ Google A2A åè®®è§„èŒƒ
- [**LangChain**](https://github.com/langchain-ai/langchain) - æ„å»º LLM åº”ç”¨çš„æ¡†æ¶
- [**AutoGen**](https://github.com/microsoft/autogen) - Microsoft çš„å¤šä»£ç†å¯¹è¯æ¡†æ¶
- [**CrewAI**](https://github.com/joaomdmoura/crewAI) - è§’è‰²æ‰®æ¼”ä»£ç†çš„åè°ƒæ¡†æ¶
- [**MCP**](https://github.com/contextco/mcp) - å·¥å…·ä½¿ç”¨ä»£ç†çš„ Model Context Protocol

## ğŸ‘¥ è´¡çŒ®è€…

æ„Ÿè°¢æ‰€æœ‰è´¡çŒ®è€…ï¼

<a href="https://github.com/themanojdesai/python-a2a/graphs/contributors">
  <img src="https://contrib.rocks/image?repo=themanojdesai/python-a2a" />
</a>

æƒ³è´¡çŒ®ï¼ŸæŸ¥çœ‹æˆ‘ä»¬çš„ [è´¡çŒ®æŒ‡å—](https://python-a2a.readthedocs.io/en/latest/contributing.html)ã€‚

## ğŸ¤ ç¤¾åŒºä¸æ”¯æŒ

- **[GitHub Issues](https://github.com/themanojdesai/python-a2a/issues)**ï¼šæŠ¥å‘Šé”™è¯¯æˆ–è¯·æ±‚åŠŸèƒ½
- **[GitHub Discussions](https://github.com/themanojdesai/python-a2a/discussions)**ï¼šæé—®å’Œåˆ†äº«æƒ³æ³•
- **[è´¡çŒ®æŒ‡å—](https://python-a2a.readthedocs.io/en/latest/contributing.html)**ï¼šå­¦ä¹ å¦‚ä½•ä¸ºé¡¹ç›®åšè´¡çŒ®
- **[ReadTheDocs](https://python-a2a.readthedocs.io/en/latest/)**ï¼šè®¿é—®æˆ‘ä»¬çš„æ–‡æ¡£ç½‘ç«™

## ğŸ“ å¼•ç”¨è¯¥é¡¹ç›®

å¦‚æœæ‚¨åœ¨ç ”ç©¶æˆ–å­¦æœ¯å·¥ä½œä¸­ä½¿ç”¨ Python A2Aï¼Œè¯·å¼•ç”¨å¦‚ä¸‹ï¼š

```
@software{desai2025pythona2a,
  author = {Desai, Manoj},
  title = {Python A2A: A Comprehensive Implementation of the Agent-to-Agent Protocol},
  url = {https://github.com/themanojdesai/python-a2a},
  version = {0.5.0},
  year = {2025},
}
```

## â­ åœ¨ GitHub ä¸Šä¸ºè¯¥é¡¹ç›®ç‚¹èµ

å¦‚æœæ‚¨å‘ç°è¿™ä¸ªåº“æœ‰ç”¨ï¼Œè¯·è€ƒè™‘åœ¨ GitHub ä¸Šä¸ºè¯¥é¡¹ç›®ç‚¹èµï¼è¿™æœ‰åŠ©äºä»–äººå‘ç°è¯¥é¡¹ç›®å¹¶æ¿€åŠ±è¿›ä¸€æ­¥å¼€å‘ã€‚

[![GitHub Repo stars](https://img.shields.io/github/stars/themanojdesai/python-a2a?style=social)](https://github.com/themanojdesai/python-a2a/stargazers)

### ç‚¹èµå†å²

[![Star History Chart](https://api.star-history.com/svg?repos=themanojdesai/python-a2a&type=Date)](https://star-history.com/#themanojdesai/python-a2a&Date)

## ğŸ™ è‡´è°¢

- [Google A2A å›¢é˜Ÿ](https://github.com/google/A2A) ä¸ºåˆ›å»º A2A åè®®
- [Contextual AI å›¢é˜Ÿ](https://contextual.ai/) ä¸º Model Context Protocol
- [LangChain å›¢é˜Ÿ](https://github.com/langchain-ai) ä¸ºå¼ºå¤§çš„ LLM æ¡†æ¶
- æ‰€æœ‰ [è´¡çŒ®è€…](https://github.com/themanojdesai/python-a2a/graphs/contributors) ä¸ºä»–ä»¬çš„å®è´µè¾“å…¥

## ğŸ‘¨â€ğŸ’» ä½œè€…

**Manoj Desai**

- GitHub: [themanojdesai](https://github.com/themanojdesai)
- LinkedIn: [themanojdesai](https://www.linkedin.com/in/themanojdesai/)
- Medium: [@the_manoj_desai](https://medium.com/@the_manoj_desai)

## ğŸ“„ è®¸å¯è¯

æœ¬é¡¹ç›®é‡‡ç”¨ MIT è®¸å¯è¯ - è¯¦è§ [LICENSE](LICENSE) æ–‡ä»¶ã€‚

---

ç”± [Manoj Desai](https://github.com/themanojdesai) ç”¨å¿ƒåˆ¶ä½œ
